{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8329940,"sourceType":"datasetVersion","datasetId":4946147}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brain teaser\n\n[Original Github REPO](https://github.com/1171-jpg/BrainTeaser)\n\n\n### Upute za pokretanje\n\n1) Pokrenuti donju liniju i viditi jel se sve moze importati\n1) Skinuti sve sto se ne moze sa `!pip install` unutar notebooka\n(pip bi trebao raditi i s condom ako je dobro namjesteno)\n    - Skinuti pytorch sa stranice [Pytorch](https://pytorch.org/get-started/locally/) - odaberite CUDA 11.8\n    ako imate graficku. Meni je bilo:\n    `> !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`\n    - Ako nemate CUDA, notebook ce biti sporiji - dovoljan za inference, \n    ali nedovoljan za fine-tuning (sreca pa to niti ne radimo, bilo bi presporo \n    i s grafickom)\n    - Skinuti huggingface transformers library:\n    `> pip install 'transformers[torch]'`\n1) Moze se sve importati na Kaggle, ovo mozda malo kasnije","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport json\nfrom datasets import load_dataset\nfrom random import shuffle\nimport random\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nimport torch\nfrom torch.nn.functional import normalize\nfrom transformers import AutoModel, AutoTokenizer\n\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport os\nfrom transformers import StoppingCriteriaList","metadata":{"execution":{"iopub.status.busy":"2024-05-11T20:06:09.616736Z","iopub.execute_input":"2024-05-11T20:06:09.617574Z","iopub.status.idle":"2024-05-11T20:06:18.484034Z","shell.execute_reply.started":"2024-05-11T20:06:09.617541Z","shell.execute_reply":"2024-05-11T20:06:18.483240Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'][:12]\nletters, len(letters)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:08.114201Z","iopub.execute_input":"2024-05-11T21:11:08.114586Z","iopub.status.idle":"2024-05-11T21:11:08.122293Z","shell.execute_reply.started":"2024-05-11T21:11:08.114554Z","shell.execute_reply":"2024-05-11T21:11:08.121351Z"},"trusted":true},"execution_count":127,"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 12)"},"metadata":{}}]},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\nimport torch\nimport logging\nimport argparse\nimport numpy as np\n\ndef getResultdata(result_data):\n    choice_to_index = {letters[i]: i for i in range(len(letters))}\n    choice_to_index[None] = len(letters)\n\n    word_play = {}\n    reverse_play = {}\n    for item in result_data:\n        item_type = item['id'].split(\"-\")[0]\n        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n        if item_type == 'WP':\n            if item_id not in word_play:\n                word_play[item_id] = [0,0,0]\n        else:\n            if item_id not in reverse_play:\n                reverse_play[item_id] = [0,0,0]\n\n    for item in result_data:\n        item_type = item['id'].split(\"-\")[0]\n        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n        ad_type = 0\n        if 'SR' in item['id']:\n            ad_type = 1\n        elif 'CR' in item['id']:\n            ad_type = 2\n        else:\n            ad_type = 0\n\n        if item_type == 'WP':\n            if choice_to_index[item['predict']] == item['label']:\n                word_play[item_id][ad_type] = 1\n        else:\n            if choice_to_index[item['predict']] == item['label']:\n                reverse_play[item_id][ad_type] = 1\n                \n    return word_play,reverse_play\n\n\ndef getMetric(data_list):\n    data_list = np.array(data_list)\n    overall_accuracy = np.sum(data_list)/3/len(data_list)\n    original_accuracy = np.sum(data_list,axis = 0)[0]/len(data_list)\n    semantic_accuracy = np.sum(data_list,axis = 0)[1]/len(data_list)\n    context_accuracy = np.sum(data_list,axis = 0)[2]/len(data_list)\n    ori_sema = np.sum([1 if item[0]==1 and item[1] == 1 else 0 for item in data_list])/len(data_list)\n    ori_sema_cont = np.sum([1 if item[0]==1 and item[1] == 1 and item[2] == 1  else 0 for item in data_list])/len(data_list)\n    \n    print(\"over_all accuracy {}\".format(overall_accuracy))\n    print(\"single_original_accuracy {}\".format(original_accuracy))\n    print(\"single_semantic_accuracy {}\".format(semantic_accuracy))\n    print(\"single_context_accuracy {}\".format(context_accuracy))\n    print(\"sr_accuracy {}\".format(ori_sema))\n    print(\"cr_accuracy {}\".format(ori_sema_cont))\n\n    return {'over_all accuracy':overall_accuracy,'original_accuracy':original_accuracy,'semantic_accuracy':semantic_accuracy,'context_accuracy':context_accuracy,'ori_sema':ori_sema,'ori_sema_cont':ori_sema_cont}\n\n\ndef getSeperateResult(word_play,reverse_thinking):\n    final_result = {}\n    word_data_list = []\n    word_data_list = list(word_play.values())\n    print('#########Wordplay##########')\n    final_result['wordplay'] = getMetric(word_data_list)\n    \n    reverse_data_list = []\n    for item in reverse_thinking.values():\n        reverse_data_list.append(item)\n    print('#########Sentence##########')   \n    final_result['sentence'] = getMetric(reverse_data_list)  \n    \n    \n    all_data = word_data_list + reverse_data_list\n    print('#########All data##########') \n    final_result['all'] = getMetric(all_data) \n    \n    return final_result","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-05-11T21:11:09.005982Z","iopub.execute_input":"2024-05-11T21:11:09.006382Z","iopub.status.idle":"2024-05-11T21:11:09.025593Z","shell.execute_reply.started":"2024-05-11T21:11:09.006352Z","shell.execute_reply":"2024-05-11T21:11:09.024453Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"def save(name=None, few_shot=False, example=format):\n    try:\n        os.mkdir('results')\n    except:\n        pass\n    model_name = model_path.split('/')[-1]\n    inserted_name = \"\" if name is None else \"_\" + name\n    i = 1\n    while True:\n        file_path = f'results/{model_name}{inserted_name}_{i}.txt'\n        try:\n            with open(file_path, 'r'):\n                i += 1\n        except:\n            with open(file_path, 'w') as file:\n                file.write(model_name+'\\n')\n                if few_shot:\n                    file.write(few_shot + '\\n')\n                if not isinstance(example, str):\n                    example = json.dumps(example)\n                file.write(example + '\\n')\n                file.write(json.dumps(final_result, indent=4))\n                return","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:09.174281Z","iopub.execute_input":"2024-05-11T21:11:09.174966Z","iopub.status.idle":"2024-05-11T21:11:09.182691Z","shell.execute_reply.started":"2024-05-11T21:11:09.174933Z","shell.execute_reply":"2024-05-11T21:11:09.181719Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":"### Dataset\n\n- Skinuti s [linka](https://drive.google.com/drive/u/0/folders/1kiFXp5fqpf8--NQJJAlBIBpfSaXTk1UY)\n\n- Staviti u folder `/data`","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:09.515685Z","iopub.execute_input":"2024-05-11T21:11:09.516596Z","iopub.status.idle":"2024-05-11T21:11:09.522301Z","shell.execute_reply.started":"2024-05-11T21:11:09.516560Z","shell.execute_reply":"2024-05-11T21:11:09.521387Z"},"trusted":true},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load the model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n# model_path = 'google/flan-t5-xxl'\n# model_path = 'google/flan-t5-xl'\n# model_path = 'google/flan-t5-large'\n# model_path = 'mistralai/Mistral-7B-Instruct-v0.2'\nmodel_path = 'microsoft/phi-2'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\nif model_path.find('flan') >= 0:\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\nelse:\n    model = AutoModelForCausalLM.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:09.850995Z","iopub.execute_input":"2024-05-11T21:11:09.851363Z","iopub.status.idle":"2024-05-11T21:11:14.413595Z","shell.execute_reply.started":"2024-05-11T21:11:09.851332Z","shell.execute_reply":"2024-05-11T21:11:14.412756Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0f3ced9ba424d0fb1331009db2dbeb6"}},"metadata":{}}]},{"cell_type":"code","source":"try:\n    model = model.to(device)\nexcept Exception as e:\n    print(e)\n    print(\"Changing device to cpu\")\n    device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:14.415375Z","iopub.execute_input":"2024-05-11T21:11:14.415680Z","iopub.status.idle":"2024-05-11T21:11:17.119534Z","shell.execute_reply.started":"2024-05-11T21:11:14.415654Z","shell.execute_reply":"2024-05-11T21:11:17.118525Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"# few_shot_examples = list(np.load(\"./{dataset_path}/data/demonstration.npy\",allow_pickle=True))\ndata_path = '/kaggle/input/brainteaser/data'\nsentence_data_path = f\"{data_path}/SP-train.npy\"\nwordplay_data_list = f\"{data_path}/WP-train.npy\"\nsentence_data_list = list(np.load(sentence_data_path,allow_pickle=True))\nwordplay_data_list = list(np.load(wordplay_data_list,allow_pickle=True))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:35.651086Z","iopub.execute_input":"2024-05-11T21:11:35.651784Z","iopub.status.idle":"2024-05-11T21:11:35.667853Z","shell.execute_reply.started":"2024-05-11T21:11:35.651755Z","shell.execute_reply":"2024-05-11T21:11:35.666866Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"test_data_list = sentence_data_list + wordplay_data_list\nprint(f\"Dataset length {len(test_data_list)}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:36.152795Z","iopub.execute_input":"2024-05-11T21:11:36.153190Z","iopub.status.idle":"2024-05-11T21:11:36.158868Z","shell.execute_reply.started":"2024-05-11T21:11:36.153160Z","shell.execute_reply":"2024-05-11T21:11:36.157771Z"},"trusted":true},"execution_count":134,"outputs":[{"name":"stdout","text":"Dataset length 903\n","output_type":"stream"}]},{"cell_type":"code","source":"newline = '\\n'\nformat = f\"\"\"Question: {\"{}\"}\nChoice:\n{''.join('(' + x + ') {}' + newline for x in letters)}\nAnswer:(\"\"\"\nprint(format)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:36.640301Z","iopub.execute_input":"2024-05-11T21:11:36.641274Z","iopub.status.idle":"2024-05-11T21:11:36.646333Z","shell.execute_reply.started":"2024-05-11T21:11:36.641238Z","shell.execute_reply":"2024-05-11T21:11:36.645312Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"Question: {}\nChoice:\n(A) {}\n(B) {}\n(C) {}\n(D) {}\n(E) {}\n(F) {}\n(G) {}\n(H) {}\n(I) {}\n(J) {}\n(K) {}\n(L) {}\n\nAnswer:(\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_single_demo(sample):\n    sample_demo = format.format(\n        sample['question'], *sample['choice_list'])\n    return sample_demo","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:37.051901Z","iopub.execute_input":"2024-05-11T21:11:37.052517Z","iopub.status.idle":"2024-05-11T21:11:37.057162Z","shell.execute_reply.started":"2024-05-11T21:11:37.052482Z","shell.execute_reply":"2024-05-11T21:11:37.056187Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"good_responses = [f'{x})' for x in letters]\ngood_responses","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:37.733152Z","iopub.execute_input":"2024-05-11T21:11:37.734042Z","iopub.status.idle":"2024-05-11T21:11:37.740342Z","shell.execute_reply.started":"2024-05-11T21:11:37.734007Z","shell.execute_reply":"2024-05-11T21:11:37.739323Z"},"trusted":true},"execution_count":137,"outputs":[{"execution_count":137,"output_type":"execute_result","data":{"text/plain":"['A)', 'B)', 'C)', 'D)', 'E)', 'F)', 'G)', 'H)', 'I)', 'J)', 'K)', 'L)']"},"metadata":{}}]},{"cell_type":"code","source":"def custom_stopping_criteria(input_ids: torch.LongTensor, score: torch.FloatTensor, **kwargs) -> bool:\n    decoded = tokenizer.decode(input_ids[0][-3:])\n    for good_response in good_responses:\n        if good_response in decoded:\n            return True\n    return False\n\nstopping_criteria = StoppingCriteriaList([custom_stopping_criteria])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:38.279959Z","iopub.execute_input":"2024-05-11T21:11:38.280891Z","iopub.status.idle":"2024-05-11T21:11:38.286471Z","shell.execute_reply.started":"2024-05-11T21:11:38.280855Z","shell.execute_reply":"2024-05-11T21:11:38.285347Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"def set_predictions(data_list):\n    for index,item in enumerate(data_list):\n        item['predict'] = None\n        for x in letters:\n            if (f'{x})') in item['response']:\n                item['predict'] = x\n\n        if item['predict'] is None:\n            print(index)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:38.951695Z","iopub.execute_input":"2024-05-11T21:11:38.952695Z","iopub.status.idle":"2024-05-11T21:11:38.958692Z","shell.execute_reply.started":"2024-05-11T21:11:38.952658Z","shell.execute_reply":"2024-05-11T21:11:38.957654Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\ndef generate(samples, tokens=10, all_tokens=True, few_shot=False):\n    for sample in tqdm(samples):\n        if few_shot:\n            text = demonstration + get_single_demo(sample)\n        else:\n            text = get_single_demo(sample)\n        inputs = tokenizer.encode(text, return_tensors=\"pt\", return_attention_mask=False).to(device)\n        original_tokens = len(inputs[0])\n        outputs = model.generate(\n            inputs,\n            pad_token_id=tokenizer.eos_token_id,\n            do_sample = False,\n            max_new_tokens=tokens,\n            stopping_criteria=stopping_criteria\n        )\n        outputs = outputs[0][0 if all_tokens else original_tokens:]\n        sample['response'] = tokenizer.decode(outputs)\n    set_predictions(samples)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:39.541033Z","iopub.execute_input":"2024-05-11T21:11:39.541416Z","iopub.status.idle":"2024-05-11T21:11:39.548915Z","shell.execute_reply.started":"2024-05-11T21:11:39.541383Z","shell.execute_reply":"2024-05-11T21:11:39.547886Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"def create_with_question(i):\n    current = test_data_list[i]\n    new = {**current}\n    choice_list = [*current['choice_list']]\n    choice_list[current['choice_order'].index(2)] = current['question'][:-1]\n    new['choice_list'] = choice_list\n    return new\n\ndef test_with_question(generated_data_list):\n    for i, sample in enumerate(generated_data_list):\n        if i == 755: continue\n        assert sample['distractor2'] not in sample['choice_list'], i\n        assert sample['question'][:-1] in sample['choice_list'], i\n\ndef create_with_k_questions(i, k):\n    current = test_data_list[i]\n    choice_list = [*current['choice_list']]\n    choice_order = [*current['choice_order']]\n    while len(choice_list) < k-1:\n        i -= 11\n        previous = test_data_list[i]\n        choice_list.insert(-1, previous['distractor1'])\n        choice_list.insert(-1, previous['distractor2'])\n    last_order = choice_list[-1]\n    choice_list = choice_list[:-1]\n#     print(current['answer'])\n    shuffle(choice_list)\n    choice_list.append(last_order)\n    try:\n        label = choice_list.index(current['answer'])\n    except Exception as e:\n        print(current['answer'])\n        label = len(choice_list)-1\n    new = {**current}\n    new['label'] = label\n    new['choice_list'] = choice_list\n    return new\n\ndef test_with_k_questions(generated_data_list):\n    for original, new in zip(test_data_list, generated_data_list):\n        assert set(original['choice_list']).issubset(set(new['choice_list'])), str(original) + '\\n'+ str(new)\n\nrandom.seed(10)\ngenerated_data_list = []\nfor i in range(len(test_data_list)):\n    new = create_with_k_questions(i, len(letters))\n    generated_data_list.append(new)\ntest_with_k_questions(generated_data_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:40.115074Z","iopub.execute_input":"2024-05-11T21:11:40.115461Z","iopub.status.idle":"2024-05-11T21:11:40.146442Z","shell.execute_reply.started":"2024-05-11T21:11:40.115431Z","shell.execute_reply":"2024-05-11T21:11:40.145279Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"They all do.\nNone of above. No dogs left the yard.\nNone of above. No dogs left the yard.\nNone of above. No birds left the branch.\n","output_type":"stream"}]},{"cell_type":"code","source":"generated_data_list[0]\nfor sample in generated_data_list:\n    if sample['id'] == 'SP-63':\n        display(sample)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:40.544048Z","iopub.execute_input":"2024-05-11T21:11:40.544417Z","iopub.status.idle":"2024-05-11T21:11:40.551716Z","shell.execute_reply.started":"2024-05-11T21:11:40.544386Z","shell.execute_reply":"2024-05-11T21:11:40.550766Z"},"trusted":true},"execution_count":142,"outputs":[{"output_type":"display_data","data":{"text/plain":"{'id': 'SP-63',\n 'question': 'Which would see most clearly in total darkness? A bat, a tiger, or an owl.',\n 'answer': 'None of above.',\n 'distractor1': 'Tiger.',\n 'distractor2': 'Bat.',\n 'distractor(unsure)': 'Owl.',\n 'label': 11,\n 'choice_list': ['The glass is too heavy.',\n  'He uses a computer to compute his actions.',\n  'He told Danny to left the bridge.',\n  'Surface tension prevents water from spilling.',\n  'Tiger.',\n  'He uses the sound to feel the direction.',\n  'His husband is not a good husband.',\n  'Owl.',\n  'Bat.',\n  'He told Danny to overturn the track.',\n  'The woman is not a good person.',\n  'None of above.'],\n 'choice_order': [3, 1, 2, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"generate(generated_data_list[:10], tokens=1000, all_tokens=False, few_shot=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:44.063118Z","iopub.execute_input":"2024-05-11T21:11:44.063491Z","iopub.status.idle":"2024-05-11T21:11:46.704758Z","shell.execute_reply.started":"2024-05-11T21:11:44.063458Z","shell.execute_reply":"2024-05-11T21:11:46.703859Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stderr","text":"100%|██████████| 10/10 [00:02<00:00,  3.80it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"for sample in generated_data_list[:5]:\n    print(\"\\n>\", sample['response'])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:46.706710Z","iopub.execute_input":"2024-05-11T21:11:46.707192Z","iopub.status.idle":"2024-05-11T21:11:46.712463Z","shell.execute_reply.started":"2024-05-11T21:11:46.707156Z","shell.execute_reply":"2024-05-11T21:11:46.711593Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"\n> J)\n\n> E)\n\n> B)\n\n> I)\n\n> A)\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(generated_data_list, tokens=20, all_tokens=False, few_shot=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:11:46.713425Z","iopub.execute_input":"2024-05-11T21:11:46.713692Z","iopub.status.idle":"2024-05-11T21:15:39.539297Z","shell.execute_reply.started":"2024-05-11T21:11:46.713669Z","shell.execute_reply":"2024-05-11T21:15:39.538321Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stderr","text":"100%|██████████| 903/903 [03:52<00:00,  3.88it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# generate(test_data_list, tokens=20, all_tokens=False, few_shot=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:15:39.541083Z","iopub.execute_input":"2024-05-11T21:15:39.541385Z","iopub.status.idle":"2024-05-11T21:15:39.545415Z","shell.execute_reply.started":"2024-05-11T21:15:39.541358Z","shell.execute_reply":"2024-05-11T21:15:39.544477Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"word_play,sentence_play = getResultdata(generated_data_list)\n# word_play,sentence_play = getResultdata(test_data_list)\nfinal_result = getSeperateResult(word_play, sentence_play)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:15:39.546742Z","iopub.execute_input":"2024-05-11T21:15:39.547350Z","iopub.status.idle":"2024-05-11T21:15:39.564847Z","shell.execute_reply.started":"2024-05-11T21:15:39.547315Z","shell.execute_reply":"2024-05-11T21:15:39.563857Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"#########Wordplay##########\nover_all accuracy 0.17424242424242425\nsingle_original_accuracy 0.14393939393939395\nsingle_semantic_accuracy 0.16666666666666666\nsingle_context_accuracy 0.21212121212121213\nsr_accuracy 0.06818181818181818\ncr_accuracy 0.03787878787878788\n#########Sentence##########\nover_all accuracy 0.28402366863905326\nsingle_original_accuracy 0.27218934911242604\nsingle_semantic_accuracy 0.24260355029585798\nsingle_context_accuracy 0.33727810650887574\nsr_accuracy 0.14201183431952663\ncr_accuracy 0.07692307692307693\n#########All data##########\nover_all accuracy 0.23588039867109634\nsingle_original_accuracy 0.2159468438538206\nsingle_semantic_accuracy 0.20930232558139536\nsingle_context_accuracy 0.2823920265780731\nsr_accuracy 0.10963455149501661\ncr_accuracy 0.059800664451827246\n","output_type":"stream"}]},{"cell_type":"code","source":"save(name=\"12_answers\", example=get_single_demo(generated_data_list[0]))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T21:15:39.566239Z","iopub.execute_input":"2024-05-11T21:15:39.566996Z","iopub.status.idle":"2024-05-11T21:15:39.573677Z","shell.execute_reply.started":"2024-05-11T21:15:39.566958Z","shell.execute_reply":"2024-05-11T21:15:39.572974Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"# save(few_shot=demonstration)\n# save()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:48:58.683077Z","iopub.execute_input":"2024-05-11T16:48:58.683856Z","iopub.status.idle":"2024-05-11T16:48:58.687987Z","shell.execute_reply.started":"2024-05-11T16:48:58.683813Z","shell.execute_reply":"2024-05-11T16:48:58.686865Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}