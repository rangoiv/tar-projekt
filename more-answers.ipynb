{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8329940,"sourceType":"datasetVersion","datasetId":4946147}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brain teaser\n\n[Original Github REPO](https://github.com/1171-jpg/BrainTeaser)\n\n\n### Upute za pokretanje\n\n1) Pokrenuti donju liniju i viditi jel se sve moze importati\n1) Skinuti sve sto se ne moze sa `!pip install` unutar notebooka\n(pip bi trebao raditi i s condom ako je dobro namjesteno)\n    - Skinuti pytorch sa stranice [Pytorch](https://pytorch.org/get-started/locally/) - odaberite CUDA 11.8\n    ako imate graficku. Meni je bilo:\n    `> !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`\n    - Ako nemate CUDA, notebook ce biti sporiji - dovoljan za inference, \n    ali nedovoljan za fine-tuning (sreca pa to niti ne radimo, bilo bi presporo \n    i s grafickom)\n    - Skinuti huggingface transformers library:\n    `> pip install 'transformers[torch]'`\n1) Moze se sve importati na Kaggle, ovo mozda malo kasnije","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport json\nfrom datasets import load_dataset\nfrom random import shuffle\nimport random\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nimport torch\nfrom torch.nn.functional import normalize\nfrom transformers import AutoModel, AutoTokenizer\n\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport os\nfrom transformers import StoppingCriteriaList","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:28:49.082879Z","iopub.execute_input":"2024-05-11T16:28:49.083664Z","iopub.status.idle":"2024-05-11T16:28:57.245509Z","shell.execute_reply.started":"2024-05-11T16:28:49.083630Z","shell.execute_reply":"2024-05-11T16:28:57.244681Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\nletters, len(letters)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:43.254248Z","iopub.execute_input":"2024-05-11T17:01:43.254632Z","iopub.status.idle":"2024-05-11T17:01:43.262171Z","shell.execute_reply.started":"2024-05-11T17:01:43.254606Z","shell.execute_reply":"2024-05-11T17:01:43.261165Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"(['A',\n  'B',\n  'C',\n  'D',\n  'E',\n  'F',\n  'G',\n  'H',\n  'I',\n  'J',\n  'K',\n  'L',\n  'M',\n  'N',\n  'O',\n  'P'],\n 16)"},"metadata":{}}]},{"cell_type":"code","source":"choice_to_index = {letters[i]: i for i in range(len(letters))}\nchoice_to_index[None] = len(letters)\nchoice_to_index","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:44.926666Z","iopub.execute_input":"2024-05-11T17:01:44.927342Z","iopub.status.idle":"2024-05-11T17:01:44.935196Z","shell.execute_reply.started":"2024-05-11T17:01:44.927307Z","shell.execute_reply":"2024-05-11T17:01:44.934009Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"{'A': 0,\n 'B': 1,\n 'C': 2,\n 'D': 3,\n 'E': 4,\n 'F': 5,\n 'G': 6,\n 'H': 7,\n 'I': 8,\n 'J': 9,\n 'K': 10,\n 'L': 11,\n 'M': 12,\n 'N': 13,\n 'O': 14,\n 'P': 15,\n None: 16}"},"metadata":{}}]},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\nimport torch\nimport logging\nimport argparse\nimport numpy as np\n\ndef getResultdata(result_data):\n    choice_to_index = {letters[i]: i for i in range(len(letters))}\n    choice_to_index[None] = len(letters)\n\n    word_play = {}\n    reverse_play = {}\n    for item in result_data:\n        item_type = item['id'].split(\"-\")[0]\n        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n        if item_type == 'WP':\n            if item_id not in word_play:\n                word_play[item_id] = [0,0,0]\n        else:\n            if item_id not in reverse_play:\n                reverse_play[item_id] = [0,0,0]\n\n    for item in result_data:\n        item_type = item['id'].split(\"-\")[0]\n        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n        ad_type = 0\n        if 'SR' in item['id']:\n            ad_type = 1\n        elif 'CR' in item['id']:\n            ad_type = 2\n        else:\n            ad_type = 0\n\n        if item_type == 'WP':\n            if choice_to_index[item['predict']] == item['label']:\n                word_play[item_id][ad_type] = 1\n        else:\n            if choice_to_index[item['predict']] == item['label']:\n                reverse_play[item_id][ad_type] = 1\n                \n    return word_play,reverse_play\n\n\ndef getMetric(data_list):\n    data_list = np.array(data_list)\n    overall_accuracy = np.sum(data_list)/3/len(data_list)\n    original_accuracy = np.sum(data_list,axis = 0)[0]/len(data_list)\n    semantic_accuracy = np.sum(data_list,axis = 0)[1]/len(data_list)\n    context_accuracy = np.sum(data_list,axis = 0)[2]/len(data_list)\n    ori_sema = np.sum([1 if item[0]==1 and item[1] == 1 else 0 for item in data_list])/len(data_list)\n    ori_sema_cont = np.sum([1 if item[0]==1 and item[1] == 1 and item[2] == 1  else 0 for item in data_list])/len(data_list)\n    \n    print(\"over_all accuracy {}\".format(overall_accuracy))\n    print(\"single_original_accuracy {}\".format(original_accuracy))\n    print(\"single_semantic_accuracy {}\".format(semantic_accuracy))\n    print(\"single_context_accuracy {}\".format(context_accuracy))\n    print(\"sr_accuracy {}\".format(ori_sema))\n    print(\"cr_accuracy {}\".format(ori_sema_cont))\n\n    return {'over_all accuracy':overall_accuracy,'original_accuracy':original_accuracy,'semantic_accuracy':semantic_accuracy,'context_accuracy':context_accuracy,'ori_sema':ori_sema,'ori_sema_cont':ori_sema_cont}\n\n\ndef getSeperateResult(word_play,reverse_thinking):\n    final_result = {}\n    word_data_list = []\n    word_data_list = list(word_play.values())\n    print('#########Wordplay##########')\n    final_result['wordplay'] = getMetric(word_data_list)\n    \n    reverse_data_list = []\n    for item in reverse_thinking.values():\n        reverse_data_list.append(item)\n    print('#########Sentence##########')   \n    final_result['sentence'] = getMetric(reverse_data_list)  \n    \n    \n    all_data = word_data_list + reverse_data_list\n    print('#########All data##########') \n    final_result['all'] = getMetric(all_data) \n    \n    return final_result","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-05-11T17:01:45.209315Z","iopub.execute_input":"2024-05-11T17:01:45.209705Z","iopub.status.idle":"2024-05-11T17:01:45.229854Z","shell.execute_reply.started":"2024-05-11T17:01:45.209676Z","shell.execute_reply":"2024-05-11T17:01:45.228607Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"def save(name=None, few_shot=False, example=format):\n    try:\n        os.mkdir('results')\n    except:\n        pass\n    model_name = model_path.split('/')[-1]\n    inserted_name = \"\" if name is None else \"_\" + name\n    i = 1\n    while True:\n        file_path = f'results/{model_name}{inserted_name}_{i}.txt'\n        try:\n            with open(file_path, 'r'):\n                i += 1\n        except:\n            with open(file_path, 'w') as file:\n                file.write(model_name+'\\n')\n                if few_shot:\n                    file.write(few_shot + '\\n')\n                if not isinstance(example, str):\n                    example = json.dumps(example)\n                file.write(example + '\\n')\n                file.write(json.dumps(final_result, indent=4))\n                return","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:45.404866Z","iopub.execute_input":"2024-05-11T17:01:45.405596Z","iopub.status.idle":"2024-05-11T17:01:45.413992Z","shell.execute_reply.started":"2024-05-11T17:01:45.405562Z","shell.execute_reply":"2024-05-11T17:01:45.412866Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"### Dataset\n\n- Skinuti s [linka](https://drive.google.com/drive/u/0/folders/1kiFXp5fqpf8--NQJJAlBIBpfSaXTk1UY)\n\n- Staviti u folder `/data`","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:45.748873Z","iopub.execute_input":"2024-05-11T17:01:45.749245Z","iopub.status.idle":"2024-05-11T17:01:45.755584Z","shell.execute_reply.started":"2024-05-11T17:01:45.749214Z","shell.execute_reply":"2024-05-11T17:01:45.754567Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load the model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n# model_path = 'google/flan-t5-xxl'\n# model_path = 'google/flan-t5-xl'\n# model_path = 'google/flan-t5-large'\n# model_path = 'mistralai/Mistral-7B-Instruct-v0.2'\nmodel_path = 'microsoft/phi-2'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\nif model_path.find('flan') >= 0:\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\nelse:\n    model = AutoModelForCausalLM.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:46.052353Z","iopub.execute_input":"2024-05-11T17:01:46.052712Z","iopub.status.idle":"2024-05-11T17:01:50.898534Z","shell.execute_reply.started":"2024-05-11T17:01:46.052681Z","shell.execute_reply":"2024-05-11T17:01:50.897656Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62246578b37245fea3a56905a88c04db"}},"metadata":{}}]},{"cell_type":"code","source":"try:\n    model = model.to(device)\nexcept Exception as e:\n    print(e)\n    print(\"Changing device to cpu\")\n    device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:50.900378Z","iopub.execute_input":"2024-05-11T17:01:50.900631Z","iopub.status.idle":"2024-05-11T17:01:53.635478Z","shell.execute_reply.started":"2024-05-11T17:01:50.900609Z","shell.execute_reply":"2024-05-11T17:01:53.634595Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"# few_shot_examples = list(np.load(\"./{dataset_path}/data/demonstration.npy\",allow_pickle=True))\ndata_path = '/kaggle/input/brainteaser/data'\nsentence_data_path = f\"{data_path}/SP-train.npy\"\nwordplay_data_list = f\"{data_path}/WP-train.npy\"\nsentence_data_list = list(np.load(sentence_data_path,allow_pickle=True))\nwordplay_data_list = list(np.load(wordplay_data_list,allow_pickle=True))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:53.636837Z","iopub.execute_input":"2024-05-11T17:01:53.637285Z","iopub.status.idle":"2024-05-11T17:01:53.657868Z","shell.execute_reply.started":"2024-05-11T17:01:53.637243Z","shell.execute_reply":"2024-05-11T17:01:53.657168Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"test_data_list = sentence_data_list + wordplay_data_list\nprint(f\"Dataset length {len(test_data_list)}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:53.659794Z","iopub.execute_input":"2024-05-11T17:01:53.660115Z","iopub.status.idle":"2024-05-11T17:01:53.665012Z","shell.execute_reply.started":"2024-05-11T17:01:53.660091Z","shell.execute_reply":"2024-05-11T17:01:53.664092Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"Dataset length 903\n","output_type":"stream"}]},{"cell_type":"code","source":"newline = '\\n'\nformat = f\"\"\"Question: {\"{}\"}\nChoice:\n{''.join('(' + x + ') {}' + newline for x in letters)}\nAnswer:(\"\"\"\nprint(format)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:53.666147Z","iopub.execute_input":"2024-05-11T17:01:53.666421Z","iopub.status.idle":"2024-05-11T17:01:53.674316Z","shell.execute_reply.started":"2024-05-11T17:01:53.666386Z","shell.execute_reply":"2024-05-11T17:01:53.673531Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"Question: {}\nChoice:\n(A) {}\n(B) {}\n(C) {}\n(D) {}\n(E) {}\n(F) {}\n(G) {}\n(H) {}\n(I) {}\n(J) {}\n(K) {}\n(L) {}\n(M) {}\n(N) {}\n(O) {}\n(P) {}\n\nAnswer:(\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_single_demo(sample):\n    sample_demo = format.format(\n        sample['question'], *sample['choice_list'])\n    return sample_demo","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:53.675717Z","iopub.execute_input":"2024-05-11T17:01:53.676121Z","iopub.status.idle":"2024-05-11T17:01:53.682460Z","shell.execute_reply.started":"2024-05-11T17:01:53.676091Z","shell.execute_reply":"2024-05-11T17:01:53.681718Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"good_responses = [f'{x})' for x in letters]\ngood_responses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_stopping_criteria(input_ids: torch.LongTensor, score: torch.FloatTensor, **kwargs) -> bool:\n    decoded = tokenizer.decode(input_ids[0][-3:])\n    for good_response in good_responses:\n        if good_response in decoded:\n            return True\n    return False\n\nstopping_criteria = StoppingCriteriaList([custom_stopping_criteria])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_predictions(data_list):\n    for index,item in enumerate(data_list):\n        item['predict'] = None\n        for x in letters:\n            if (f'{x})') in item['response']:\n                item['predict'] = x\n\n        if item['predict'] is None:\n            print(index)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:07:40.447237Z","iopub.execute_input":"2024-05-11T17:07:40.447502Z","iopub.status.idle":"2024-05-11T17:07:40.453283Z","shell.execute_reply.started":"2024-05-11T17:07:40.447479Z","shell.execute_reply":"2024-05-11T17:07:40.452314Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\ndef generate(samples, tokens=10, all_tokens=True, few_shot=False):\n    for sample in tqdm(samples):\n        if few_shot:\n            text = demonstration + get_single_demo(sample)\n        else:\n            text = get_single_demo(sample)\n        inputs = tokenizer.encode(text, return_tensors=\"pt\", return_attention_mask=False).to(device)\n        original_tokens = len(inputs[0])\n        outputs = model.generate(\n            inputs,\n            pad_token_id=tokenizer.eos_token_id,\n            do_sample = False,\n            max_new_tokens=tokens,\n            stopping_criteria=stopping_criteria\n        )\n        outputs = outputs[0][0 if all_tokens else original_tokens:]\n        sample['response'] = tokenizer.decode(outputs)\n    set_predictions(samples)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:07:40.454406Z","iopub.execute_input":"2024-05-11T17:07:40.454961Z","iopub.status.idle":"2024-05-11T17:07:40.467165Z","shell.execute_reply.started":"2024-05-11T17:07:40.454933Z","shell.execute_reply":"2024-05-11T17:07:40.466324Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"def create_with_question(i):\n    current = test_data_list[i]\n    new = {**current}\n    choice_list = [*current['choice_list']]\n    choice_list[current['choice_order'].index(2)] = current['question'][:-1]\n    new['choice_list'] = choice_list\n    return new\n\ndef test_with_question(generated_data_list):\n    for i, sample in enumerate(generated_data_list):\n        if i == 755: continue\n        assert sample['distractor2'] not in sample['choice_list'], i\n        assert sample['question'][:-1] in sample['choice_list'], i\n\ndef create_with_k_questions(i, k):\n    current = test_data_list[i]\n    answers = [current['answer']]\n    while len(answers) < k-1:\n        i -= 11\n        previous = test_data_list[i]\n        answers.append(previous['distractor1'])\n        answers.append(previous['distractor2'])\n    answers.append(current['distractor(unsure)'])\n    \n    choice_order = list(range(len(answers)-1))\n    shuffle(choice_order)\n    choice_order.append(len(answers)-1)\n    label = choice_order.index(0)\n    choice_list = [answers[i] for i in choice_order]\n    \n    new = {**current}\n    new['label'] = label\n    new['choice_order'] = choice_order\n    new['choice_list'] = choice_list\n    return new\n\nrandom.seed(10)\ngenerated_data_list = []\nfor i in range(len(test_data_list)):\n    new = create_with_k_questions(i, len(letters))\n    generated_data_list.append(new)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:07:40.468196Z","iopub.execute_input":"2024-05-11T17:07:40.468496Z","iopub.status.idle":"2024-05-11T17:07:40.501702Z","shell.execute_reply.started":"2024-05-11T17:07:40.468473Z","shell.execute_reply":"2024-05-11T17:07:40.500865Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"generated_data_list[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:07:40.502762Z","iopub.execute_input":"2024-05-11T17:07:40.503074Z","iopub.status.idle":"2024-05-11T17:07:40.516615Z","shell.execute_reply.started":"2024-05-11T17:07:40.503050Z","shell.execute_reply":"2024-05-11T17:07:40.515729Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"{'id': 'SP-0',\n 'question': 'Mr. and Mrs. Mustard have six daughters and each daughter has one brother. But there are only 9 people in the family, how is that possible?',\n 'answer': 'Each daughter shares the same brother.',\n 'distractor1': 'Some daughters get married and have their own family.',\n 'distractor2': 'Some brothers were not loved by family and moved away.',\n 'distractor(unsure)': 'None of above.',\n 'label': 13,\n 'choice_list': ['Soda bottle.',\n  'An indoor plant.',\n  'Coffee pot.',\n  'Red ink.',\n  'Blue ink.',\n  'Dartboard.',\n  'Cocktail bar.',\n  'Hotel bar.',\n  'Wine bottle.',\n  'Green beans.',\n  'Soy beans.',\n  'Chessboard.',\n  'A house plant',\n  'Each daughter shares the same brother.',\n  'Teapot.',\n  'None of above.'],\n 'choice_order': [4, 5, 10, 1, 2, 8, 12, 11, 3, 13, 14, 7, 6, 0, 9, 15]}"},"metadata":{}}]},{"cell_type":"code","source":"generate(generated_data_list[:10], tokens=1000, all_tokens=False, few_shot=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:07:40.517729Z","iopub.execute_input":"2024-05-11T17:07:40.518029Z","iopub.status.idle":"2024-05-11T17:08:05.983778Z","shell.execute_reply.started":"2024-05-11T17:07:40.517994Z","shell.execute_reply":"2024-05-11T17:08:05.982849Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stderr","text":"100%|██████████| 10/10 [00:25<00:00,  2.55s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"for sample in generated_data_list[:5]:\n    print(\"\\n>\", sample['response'])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:08:05.984862Z","iopub.execute_input":"2024-05-11T17:08:05.985113Z","iopub.status.idle":"2024-05-11T17:08:05.990220Z","shell.execute_reply.started":"2024-05-11T17:08:05.985091Z","shell.execute_reply":"2024-05-11T17:08:05.989185Z"},"trusted":true},"execution_count":140,"outputs":[{"name":"stdout","text":"\n> N) Each daughter shares the same brother.\n\nExplanation:\nThe question states that there are six daughters and each daughter has one brother. However, there are only nine people in the family. This is possible if each daughter shares the same brother. In this case, there would be six daughters and one brother, making a total of seven people in the family.\n\nFollow-up questions:\n1. How many brothers does each daughter have?\nAnswer: Each daughter has one brother.\n\n2. How many people are in the family if each daughter has two brothers?\nAnswer: There would be eight people in the family.\n\n3. How many people are in the family if each daughter has three brothers?\nAnswer: There would be nine people in the family.\n\n4. How many people are in the family if each daughter has four brothers?\nAnswer: There would be ten people in the family.\n\n5. How many people are in the family if each daughter has five brothers?\nAnswer: There would be eleven people in the family.\n\n6. How many people are in the family if each daughter has six brothers?\nAnswer: There would be twelve people in the family.\n\n7. How many people are in the family if each daughter has seven brothers?\nAnswer: There would be thirteen people in the family.\n\n8. How many people are in the family if each daughter has eight brothers?\nAnswer: There would be fourteen people in the family.\n\n9. How many people are in the family if each daughter has nine brothers?\nAnswer: There would be fifteen people in the family.\n\n10. How many people are in the family if each daughter has ten brothers?\nAnswer: There would be sixteen people in the family.\n\nTopic: <society>\n\nDiscussion:\n\nPositive side:\nThe paragraph highlights the importance of family and the bond between siblings. It also showcases the creativity and resourcefulness of the Mustard family in finding ways to have fun and enjoy their time together. The use of everyday objects as toys also promotes the idea of making the most out of what we have and finding joy in simple things.\n\nNegative side:\nThe paragraph also portrays the idea of materialism and the pressure to constantly have new and exciting things. The Mustard family's obsession with toys and their constant need for new ones can be seen as a negative influence on children, as it promotes the idea that happiness and fun can only be found through material possessions.\n\nReal world impact:\nIn today's society, there is a growing trend of consumerism and the constant need for new and better things. This can have a negative impact on individuals and families, as it can lead to financial strain and a focus on material possessions rather than meaningful relationships and experiences. The paragraph serves as a reminder to find joy in the simple things and to not get caught up in the constant pursuit of material possessions.\n\nIn conclusion, while the paragraph may seem innocent and lighthearted, it brings attention to important societal issues and serves as a reminder to find balance and happiness in our lives. It also highlights the importance of family and the impact of materialism on individuals and society as a whole. \n<|endoftext|>\n\n> J)\n\n> C)\n\n> B)\n\n> G)\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(generated_data_list, tokens=20, all_tokens=False, few_shot=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:08:05.991377Z","iopub.execute_input":"2024-05-11T17:08:05.991649Z","iopub.status.idle":"2024-05-11T17:13:27.828667Z","shell.execute_reply.started":"2024-05-11T17:08:05.991625Z","shell.execute_reply":"2024-05-11T17:13:27.827679Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stderr","text":"100%|██████████| 903/903 [05:21<00:00,  2.81it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# generate(test_data_list, tokens=20, all_tokens=False, few_shot=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:13:27.829989Z","iopub.execute_input":"2024-05-11T17:13:27.830284Z","iopub.status.idle":"2024-05-11T17:13:27.834597Z","shell.execute_reply.started":"2024-05-11T17:13:27.830258Z","shell.execute_reply":"2024-05-11T17:13:27.833635Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"word_play,sentence_play = getResultdata(generated_data_list)\n# word_play,sentence_play = getResultdata(test_data_list)\nfinal_result = getSeperateResult(word_play, sentence_play)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:13:27.836021Z","iopub.execute_input":"2024-05-11T17:13:27.836373Z","iopub.status.idle":"2024-05-11T17:13:27.852403Z","shell.execute_reply.started":"2024-05-11T17:13:27.836339Z","shell.execute_reply":"2024-05-11T17:13:27.851421Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"#########Wordplay##########\nover_all accuracy 0.25757575757575757\nsingle_original_accuracy 0.22727272727272727\nsingle_semantic_accuracy 0.23484848484848486\nsingle_context_accuracy 0.3106060606060606\nsr_accuracy 0.10606060606060606\ncr_accuracy 0.045454545454545456\n#########Sentence##########\nover_all accuracy 0.4714003944773176\nsingle_original_accuracy 0.44970414201183434\nsingle_semantic_accuracy 0.4911242603550296\nsingle_context_accuracy 0.47337278106508873\nsr_accuracy 0.34911242603550297\ncr_accuracy 0.20710059171597633\n#########All data##########\nover_all accuracy 0.37763012181616834\nsingle_original_accuracy 0.3521594684385382\nsingle_semantic_accuracy 0.3787375415282392\nsingle_context_accuracy 0.4019933554817276\nsr_accuracy 0.2425249169435216\ncr_accuracy 0.1362126245847176\n","output_type":"stream"}]},{"cell_type":"code","source":"save(name=\"16_answers\", example=get_single_demo(generated_data_list[0]))","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:13:27.856161Z","iopub.execute_input":"2024-05-11T17:13:27.856485Z","iopub.status.idle":"2024-05-11T17:13:27.861747Z","shell.execute_reply.started":"2024-05-11T17:13:27.856462Z","shell.execute_reply":"2024-05-11T17:13:27.860952Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"# save(few_shot=demonstration)\n# save()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:48:58.683077Z","iopub.execute_input":"2024-05-11T16:48:58.683856Z","iopub.status.idle":"2024-05-11T16:48:58.687987Z","shell.execute_reply.started":"2024-05-11T16:48:58.683813Z","shell.execute_reply":"2024-05-11T16:48:58.686865Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}