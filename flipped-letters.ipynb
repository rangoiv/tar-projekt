{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8329940,"sourceType":"datasetVersion","datasetId":4946147}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brain teaser\n\n[Original Github REPO](https://github.com/1171-jpg/BrainTeaser)\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport json\nfrom datasets import load_dataset\nfrom random import shuffle\nimport random\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nimport torch\nfrom torch.nn.functional import normalize\nfrom transformers import AutoModel, AutoTokenizer\n\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport os\nfrom transformers import StoppingCriteriaList","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:58:31.745547Z","iopub.execute_input":"2024-05-16T15:58:31.745892Z","iopub.status.idle":"2024-05-16T15:58:38.754003Z","shell.execute_reply.started":"2024-05-16T15:58:31.745864Z","shell.execute_reply":"2024-05-16T15:58:38.753003Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Ako imamo vise ponudenih odgovora od 4, da postupak bude automatski u svim funkcijama\nletters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'][3::-1]\nletters, len(letters)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:58:42.083049Z","iopub.execute_input":"2024-05-16T15:58:42.083587Z","iopub.status.idle":"2024-05-16T15:58:42.091871Z","shell.execute_reply.started":"2024-05-16T15:58:42.083560Z","shell.execute_reply":"2024-05-16T15:58:42.090859Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(['D', 'C', 'B', 'A'], 4)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Metrike\n\nPreuzeto direktno s njihovog repoa","metadata":{}},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\nimport torch\nimport logging\nimport argparse\nimport numpy as np\n\ndef getResultdata(result_data):\n    choice_to_index = {letters[i]: i for i in range(len(letters))}\n    choice_to_index[None] = len(letters)\n\n    word_play = {}\n    reverse_play = {}\n    for item in result_data:\n        item_type = item['id'].split(\"-\")[0]\n        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n        if item_type == 'WP':\n            if item_id not in word_play:\n                word_play[item_id] = [0,0,0]\n        else:\n            if item_id not in reverse_play:\n                reverse_play[item_id] = [0,0,0]\n\n    for item in result_data:\n        item_type = item['id'].split(\"-\")[0]\n        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n        ad_type = 0\n        if 'SR' in item['id']:\n            ad_type = 1\n        elif 'CR' in item['id']:\n            ad_type = 2\n        else:\n            ad_type = 0\n\n        if item_type == 'WP':\n            if choice_to_index[item['predict']] == item['label']:\n                word_play[item_id][ad_type] = 1\n        else:\n            if choice_to_index[item['predict']] == item['label']:\n                reverse_play[item_id][ad_type] = 1\n                \n    return word_play,reverse_play\n\n\ndef getMetric(data_list):\n    data_list = np.array(data_list)\n    overall_accuracy = np.sum(data_list)/3/len(data_list)\n    original_accuracy = np.sum(data_list,axis = 0)[0]/len(data_list)\n    semantic_accuracy = np.sum(data_list,axis = 0)[1]/len(data_list)\n    context_accuracy = np.sum(data_list,axis = 0)[2]/len(data_list)\n    ori_sema = np.sum([1 if item[0]==1 and item[1] == 1 else 0 for item in data_list])/len(data_list)\n    ori_sema_cont = np.sum([1 if item[0]==1 and item[1] == 1 and item[2] == 1  else 0 for item in data_list])/len(data_list)\n    \n    print(\"over_all accuracy {}\".format(overall_accuracy))\n    print(\"single_original_accuracy {}\".format(original_accuracy))\n    print(\"single_semantic_accuracy {}\".format(semantic_accuracy))\n    print(\"single_context_accuracy {}\".format(context_accuracy))\n    print(\"sr_accuracy {}\".format(ori_sema))\n    print(\"cr_accuracy {}\".format(ori_sema_cont))\n\n    return {'over_all accuracy':overall_accuracy,'original_accuracy':original_accuracy,'semantic_accuracy':semantic_accuracy,'context_accuracy':context_accuracy,'ori_sema':ori_sema,'ori_sema_cont':ori_sema_cont}\n\n\ndef getSeperateResult(word_play,reverse_thinking):\n    final_result = {}\n    word_data_list = []\n    word_data_list = list(word_play.values())\n    print('#########Wordplay##########')\n    final_result['wordplay'] = getMetric(word_data_list)\n    \n    reverse_data_list = []\n    for item in reverse_thinking.values():\n        reverse_data_list.append(item)\n    print('#########Sentence##########')   \n    final_result['sentence'] = getMetric(reverse_data_list)  \n    \n    \n    all_data = word_data_list + reverse_data_list\n    print('#########All data##########') \n    final_result['all'] = getMetric(all_data) \n    \n    return final_result","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-05-16T15:58:43.824688Z","iopub.execute_input":"2024-05-16T15:58:43.825498Z","iopub.status.idle":"2024-05-16T15:58:43.843206Z","shell.execute_reply.started":"2024-05-16T15:58:43.825467Z","shell.execute_reply":"2024-05-16T15:58:43.842245Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Spremanje datoteka\n\nAutomatski dodaje +1 na naziv ako vec postoji takva datoteka\n\nUzima format model_name + name + redni broj za datoteku\n\nUnutra pise prvi testni primjer (example) i rezultate","metadata":{}},{"cell_type":"code","source":"def save(name=None, few_shot=False, example=format):\n    try:\n        os.mkdir('results')\n    except:\n        pass\n    model_name = model_path.split('/')[-1]\n    inserted_name = \"\" if name is None else \"_\" + name\n    i = 1\n    while True:\n        file_path = f'results/{model_name}{inserted_name}_{i}.txt'\n        try:\n            with open(file_path, 'r'):\n                i += 1\n        except:\n            with open(file_path, 'w') as file:\n                file.write(model_name+'\\n')\n                if few_shot:\n                    file.write(few_shot + '\\n')\n                if not isinstance(example, str):\n                    example = json.dumps(example)\n                file.write(example + '\\n')\n                file.write(json.dumps(final_result, indent=4))\n                return","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:58:45.384742Z","iopub.execute_input":"2024-05-16T15:58:45.385602Z","iopub.status.idle":"2024-05-16T15:58:45.393807Z","shell.execute_reply.started":"2024-05-16T15:58:45.385557Z","shell.execute_reply":"2024-05-16T15:58:45.392887Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Load the model\n\nLogin kako bi se mogli ucitati napredniji modeli","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:58:46.552419Z","iopub.execute_input":"2024-05-16T15:58:46.553073Z","iopub.status.idle":"2024-05-16T15:58:46.582996Z","shell.execute_reply.started":"2024-05-16T15:58:46.553034Z","shell.execute_reply":"2024-05-16T15:58:46.582131Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:58:47.140451Z","iopub.execute_input":"2024-05-16T15:58:47.140830Z","iopub.status.idle":"2024-05-16T15:58:47.165807Z","shell.execute_reply.started":"2024-05-16T15:58:47.140802Z","shell.execute_reply":"2024-05-16T15:58:47.164908Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b072060859c7485d988e011f6d69dad9"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n# model_path = 'google/flan-t5-xxl'\n# model_path = 'google/flan-t5-xl'\n# model_path = 'google/flan-t5-large'\n# model_path = 'mistralai/Mistral-7B-Instruct-v0.2'\n# model_path = 'microsoft/phi-2'\n# model_path = 'microsoft/Phi-3-mini-128k-instruct'\nmodel_path = 'microsoft/Phi-3-mini-4k-instruct'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n\nif model_path.find('flan') >= 0:\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_path, trust_remote_code=True, device_map = 'cuda')\nelse:\n    model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, device_map = 'cuda')","metadata":{"execution":{"iopub.status.busy":"2024-05-16T15:58:51.610084Z","iopub.execute_input":"2024-05-16T15:58:51.610994Z","iopub.status.idle":"2024-05-16T16:01:23.795644Z","shell.execute_reply.started":"2024-05-16T15:58:51.610960Z","shell.execute_reply":"2024-05-16T16:01:23.794865Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4046efbc48fd484abc46ac6092a502a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"474b58dd90f74340b2063e290a4d5712"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9d6bb1b53af4ad7979660c7dfe81ac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dc179ebb5fb43febe02fe676eddca68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b36468ed0984d2bbfb251aa9000b308"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8914d888435d4327b68ca3ba4d5b6656"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a6b640eade74c8e84b32813e8565b19"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b5743262e8041f3bb98dbaac125dec4"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b001b1d7cbe24d5185e9c3d62a23fdfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b11ac2e8c0a442b694d2565b100eff0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"213a09a7b2054153bcedd449b116062e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"266efe97370c4c71961b8819edb1247d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c88d89ed999447889af8e7ab1f26515a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e351909c189040718b61c72fe244e2b2"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Dataset\n\n- Skinuti s [linka](https://drive.google.com/drive/u/0/folders/1kiFXp5fqpf8--NQJJAlBIBpfSaXTk1UY)\n\n- Staviti u folder `/data`, ako na Kaggleu, onda napraviti svoj dataset te ga dodati pod input","metadata":{}},{"cell_type":"code","source":"# few_shot_examples = list(np.load(\"./{dataset_path}/data/demonstration.npy\",allow_pickle=True))\ndata_path = '/kaggle/input/brainteaser/data'\nsentence_data_path = f\"{data_path}/SP-train.npy\"\nwordplay_data_list = f\"{data_path}/WP-train.npy\"\nsentence_data_list = list(np.load(sentence_data_path,allow_pickle=True))\nwordplay_data_list = list(np.load(wordplay_data_list,allow_pickle=True))\n\ntest_data_list = sentence_data_list + wordplay_data_list\nprint(f\"Dataset length {len(test_data_list)}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:23.797474Z","iopub.execute_input":"2024-05-16T16:01:23.798411Z","iopub.status.idle":"2024-05-16T16:01:23.823605Z","shell.execute_reply.started":"2024-05-16T16:01:23.798374Z","shell.execute_reply":"2024-05-16T16:01:23.822825Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Dataset length 903\n","output_type":"stream"}]},{"cell_type":"code","source":"newline = '\\n'\nformat = f\"\"\"Question: {\"{}\"}\nChoice:\n{''.join('(' + x + ') {}' + newline for x in letters)}\nAnswer:(\"\"\"\nprint(format)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:23.824629Z","iopub.execute_input":"2024-05-16T16:01:23.824889Z","iopub.status.idle":"2024-05-16T16:01:23.936032Z","shell.execute_reply.started":"2024-05-16T16:01:23.824867Z","shell.execute_reply":"2024-05-16T16:01:23.935072Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Question: {}\nChoice:\n(D) {}\n(C) {}\n(B) {}\n(A) {}\n\nAnswer:(\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_single_demo(sample):\n    sample_demo = format.format(\n        sample['question'], *sample['choice_list'])\n    return sample_demo\n\ngood_responses = [f'{x})' for x in letters]\nprint(\"good_responses\", good_responses)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:23.938126Z","iopub.execute_input":"2024-05-16T16:01:23.938461Z","iopub.status.idle":"2024-05-16T16:01:23.945487Z","shell.execute_reply.started":"2024-05-16T16:01:23.938427Z","shell.execute_reply":"2024-05-16T16:01:23.944551Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"good_responses ['D)', 'C)', 'B)', 'A)']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Generiranje dataseta\n\n### Pomocne funkcije","metadata":{}},{"cell_type":"code","source":"def set_predictions(data_list):\n    \"\"\"Uzima response i parsira ga tako da pod predict stavi slovo koje je napisano\"\"\"\n    for index,item in enumerate(data_list):\n        item['predict'] = None\n        for x in letters:\n            if (f'{x})') in item['response']:\n                item['predict'] = x\n\n        if item['predict'] is None:\n            print(index)\n\ndef custom_stopping_criteria(input_ids: torch.LongTensor, score: torch.FloatTensor, **kwargs) -> bool:\n    \"\"\"\n    Funkcija kako bi se dinamicki prepoznalo kad treba prestati generirati tekst:\n    ne nakon fiksnog broja tokena, vec kad model napise rjesenje. Najcesce\n    ce to ipak biti medu prva dva tokena\n    \"\"\"\n    decoded = tokenizer.decode(input_ids[0][-3:])\n    for good_response in good_responses:\n        if good_response in decoded:\n            return True\n    return False\n\nstopping_criteria = StoppingCriteriaList([custom_stopping_criteria])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:23.946592Z","iopub.execute_input":"2024-05-16T16:01:23.946897Z","iopub.status.idle":"2024-05-16T16:01:23.955754Z","shell.execute_reply.started":"2024-05-16T16:01:23.946874Z","shell.execute_reply":"2024-05-16T16:01:23.954959Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def generate(samples, tokens=10, all_tokens=True, few_shot=False):\n    for sample in tqdm(samples):\n        if few_shot:\n            text = demonstration + get_single_demo(sample)\n        else:\n            text = get_single_demo(sample)\n        inputs = tokenizer.encode(text, return_tensors=\"pt\", return_attention_mask=False).to(device)\n        original_tokens = len(inputs[0])\n        outputs = model.generate(\n            inputs,\n            pad_token_id=tokenizer.eos_token_id,\n            do_sample = False,\n            max_new_tokens=tokens,\n            stopping_criteria=stopping_criteria\n        )\n        outputs = outputs[0][0 if all_tokens else original_tokens:]\n        sample['response'] = tokenizer.decode(outputs)\n    set_predictions(samples)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:23.956923Z","iopub.execute_input":"2024-05-16T16:01:23.957498Z","iopub.status.idle":"2024-05-16T16:01:23.968707Z","shell.execute_reply.started":"2024-05-16T16:01:23.957466Z","shell.execute_reply":"2024-05-16T16:01:23.968005Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def create_with_question(i):\n    \"\"\"Generira sample tako da zamijeni drugi distraction s pitanjem\"\"\"\n    current = test_data_list[i]\n    new = {**current}\n    choice_list = [*current['choice_list']]\n    choice_list[current['choice_order'].index(2)] = current['question'][:-1]\n    new['choice_list'] = choice_list\n    return new\n\ndef test_with_question(generated_data_list):\n    \"\"\"Testira radi li generiranje ispravno\"\"\"\n    for i, sample in enumerate(generated_data_list):\n        if i in [227, 755, 714, 715, 716]: continue\n        assert sample['distractor2'] not in sample['choice_list'], i\n        assert sample['question'][:-1] in sample['choice_list'], i\n        assert str(sample['answer']) in sample['choice_list'], i\n        assert str(sample['distractor1']) in sample['choice_list'], i\n\ndef count_with_question(generated_data_list):\n    \"\"\"Broji koliko puta je model predvidio da je pitanje odgovor na pitanje\"\"\"\n    total = 0\n    for sample in generated_data_list:\n        if sample['choice_list'][letters.index(sample['predict'])] == sample['question'][:-1]:\n            total += 1\n    return total, len(generated_data_list)\n\ndef create_with_ordered_correct_answer(i, target_position):\n    \"\"\"Generira sample tako da je odgovor uvijek na target position\"\"\"\n    current = test_data_list[i]\n    new = {**current}\n    choice_list = [*current['choice_list']]\n    correct_answer = choice_list[current[\"label\"]]\n    choice_list.remove(correct_answer)\n    choice_list.insert(target_position,correct_answer)\n    new['choice_list'] = choice_list\n    new['label'] = target_position\n    return new\n\ndef test_with_ordered_correct_answer(generated_data_list):\n    \"\"\"Testira radi li generiranje ispravno\"\"\"\n    for original, new in zip(test_data_list, generated_data_list):\n        assert set(original['choice_list']) == set(new['choice_list']), str(original) + '\\n'+ str(new)\n        assert new['choice_list'][new['label']] == original['choice_list'][original['label']]\n\ndef create_with_k_answers(i, k):\n    \"\"\"Generira sample tako da doda kao dodatne odgovore distractore iz drugih pitanja\"\"\"\n    current = test_data_list[i]\n    choice_list = [*current['choice_list']]\n    choice_order = [*current['choice_order']]\n    while len(choice_list) < k-1:\n        i -= 11\n        previous = test_data_list[i]\n        choice_list.insert(-1, previous['distractor1'])\n        choice_list.insert(-1, previous['distractor2'])\n    last_order = choice_list[-1]\n    choice_list = choice_list[:-1]\n#     print(current['answer'])\n    shuffle(choice_list)\n    choice_list.append(last_order)\n    try:\n        label = choice_list.index(current['answer'])\n    except Exception as e:\n        print(current['answer'])\n        label = len(choice_list)-1\n    new = {**current}\n    new['label'] = label\n    new['choice_list'] = choice_list\n    return new\n\ndef test_with_k_answers(generated_data_list):\n    \"\"\"Testira radi li generiranje ispravno\"\"\"\n    for original, new in zip(test_data_list, generated_data_list):\n        assert set(original['choice_list']).issubset(set(new['choice_list'])), str(original) + '\\n'+ str(new)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:23.969719Z","iopub.execute_input":"2024-05-16T16:01:23.970022Z","iopub.status.idle":"2024-05-16T16:01:23.987208Z","shell.execute_reply.started":"2024-05-16T16:01:23.969999Z","shell.execute_reply":"2024-05-16T16:01:23.986477Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"random.seed(10)\ngenerated_data_list = []\nfor i in range(len(test_data_list)):\n#     new = create_with_k_answers(i, len(letters))\n    new = create_with_ordered_correct_answer(i, 0)\n#     new = create_with_question(i)\n    generated_data_list.append(new)\n# test_with_question(generated_data_list)\ntest_with_ordered_correct_answer(generated_data_list)\ntest_with_k_answers(generated_data_list)\ngenerated_data_list[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:23.988234Z","iopub.execute_input":"2024-05-16T16:01:23.988493Z","iopub.status.idle":"2024-05-16T16:01:24.006812Z","shell.execute_reply.started":"2024-05-16T16:01:23.988471Z","shell.execute_reply":"2024-05-16T16:01:24.005999Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'id': 'SP-0',\n 'question': 'Mr. and Mrs. Mustard have six daughters and each daughter has one brother. But there are only 9 people in the family, how is that possible?',\n 'answer': 'Each daughter shares the same brother.',\n 'distractor1': 'Some daughters get married and have their own family.',\n 'distractor2': 'Some brothers were not loved by family and moved away.',\n 'distractor(unsure)': 'None of above.',\n 'label': 0,\n 'choice_list': ['Each daughter shares the same brother.',\n  'Some daughters get married and have their own family.',\n  'Some brothers were not loved by family and moved away.',\n  'None of above.'],\n 'choice_order': [1, 0, 2, 3]}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testiranje","metadata":{}},{"cell_type":"code","source":"generate(test_data_list[:10], tokens=1000, all_tokens=False, few_shot=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:35.266022Z","iopub.execute_input":"2024-05-16T16:01:35.266898Z","iopub.status.idle":"2024-05-16T16:01:39.736444Z","shell.execute_reply.started":"2024-05-16T16:01:35.266865Z","shell.execute_reply":"2024-05-16T16:01:39.735382Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.24it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"for sample in test_data_list[:5]:\n    print(\"\\n>\", sample['response'])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:39.738282Z","iopub.execute_input":"2024-05-16T16:01:39.738665Z","iopub.status.idle":"2024-05-16T16:01:39.744560Z","shell.execute_reply.started":"2024-05-16T16:01:39.738631Z","shell.execute_reply":"2024-05-16T16:01:39.743550Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\n> C)\n\n> B)\n\n> C)\n\n> B)\n\n> C)\n","output_type":"stream"}]},{"cell_type":"code","source":"generate(test_data_list, tokens=20, all_tokens=False, few_shot=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:01:44.457718Z","iopub.execute_input":"2024-05-16T16:01:44.458458Z","iopub.status.idle":"2024-05-16T16:04:55.586635Z","shell.execute_reply.started":"2024-05-16T16:01:44.458424Z","shell.execute_reply":"2024-05-16T16:04:55.585718Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 903/903 [03:11<00:00,  4.72it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"word_play,sentence_play = getResultdata(test_data_list)\n# word_play,sentence_play = getResultdata(test_data_list)\nfinal_result = getSeperateResult(word_play, sentence_play)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:04:55.588540Z","iopub.execute_input":"2024-05-16T16:04:55.588981Z","iopub.status.idle":"2024-05-16T16:04:55.598469Z","shell.execute_reply.started":"2024-05-16T16:04:55.588946Z","shell.execute_reply":"2024-05-16T16:04:55.597450Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"#########Wordplay##########\nover_all accuracy 0.23989898989898992\nsingle_original_accuracy 0.24242424242424243\nsingle_semantic_accuracy 0.24242424242424243\nsingle_context_accuracy 0.23484848484848486\nsr_accuracy 0.14393939393939395\ncr_accuracy 0.03787878787878788\n#########Sentence##########\nover_all accuracy 0.5542406311637081\nsingle_original_accuracy 0.5976331360946746\nsingle_semantic_accuracy 0.4970414201183432\nsingle_context_accuracy 0.5680473372781065\nsr_accuracy 0.4556213017751479\ncr_accuracy 0.2958579881656805\n#########All data##########\nover_all accuracy 0.4163898117386489\nsingle_original_accuracy 0.4418604651162791\nsingle_semantic_accuracy 0.3853820598006645\nsingle_context_accuracy 0.4219269102990033\nsr_accuracy 0.31893687707641194\ncr_accuracy 0.18272425249169436\n","output_type":"stream"}]},{"cell_type":"code","source":"save(name=\"flipped-letters\", example=get_single_demo(test_data_list[0]))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:04:55.599633Z","iopub.execute_input":"2024-05-16T16:04:55.599907Z","iopub.status.idle":"2024-05-16T16:04:55.607914Z","shell.execute_reply.started":"2024-05-16T16:04:55.599885Z","shell.execute_reply":"2024-05-16T16:04:55.607094Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# save(few_shot=demonstration)\n# save()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:48:58.683077Z","iopub.execute_input":"2024-05-11T16:48:58.683856Z","iopub.status.idle":"2024-05-11T16:48:58.687987Z","shell.execute_reply.started":"2024-05-11T16:48:58.683813Z","shell.execute_reply":"2024-05-11T16:48:58.686865Z"},"trusted":true},"execution_count":67,"outputs":[]}]}