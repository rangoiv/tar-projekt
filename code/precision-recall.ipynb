{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Brain teaser\n","\n","[Original Github REPO](https://github.com/1171-jpg/BrainTeaser)\n","\n","[Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T20:36:34.118555Z","iopub.status.busy":"2024-10-14T20:36:34.118174Z","iopub.status.idle":"2024-10-14T20:37:12.002278Z","shell.execute_reply":"2024-10-14T20:37:12.001052Z","shell.execute_reply.started":"2024-10-14T20:36:34.118514Z"},"trusted":true},"outputs":[],"source":["!pip install -q -U langchain transformers bitsandbytes accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T20:37:12.004818Z","iopub.status.busy":"2024-10-14T20:37:12.004544Z","iopub.status.idle":"2024-10-14T20:37:30.295698Z","shell.execute_reply":"2024-10-14T20:37:30.294890Z","shell.execute_reply.started":"2024-10-14T20:37:12.004793Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import json\n","from datasets import load_dataset\n","from random import shuffle\n","import random\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","\n","import torch\n","from torch.nn.functional import normalize\n","from transformers import AutoModel, AutoTokenizer\n","\n","from tqdm.auto import tqdm\n","import numpy as np\n","import os\n","from transformers import StoppingCriteriaList\n","\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","import gc\n","from sklearn.metrics import precision_recall_curve\n","\n","import json\n","from tqdm import tqdm\n","import torch\n","import logging\n","import argparse\n","import numpy as np"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T20:37:30.297257Z","iopub.status.busy":"2024-10-14T20:37:30.296718Z","iopub.status.idle":"2024-10-14T20:37:30.306946Z","shell.execute_reply":"2024-10-14T20:37:30.305862Z","shell.execute_reply.started":"2024-10-14T20:37:30.297225Z"},"trusted":true},"outputs":[],"source":["dirname= 'resultsnew'\n","pickle_dir = 'pickled_results'\n","\n","def create_dir(name):\n","    try:\n","        os.mkdir(name)\n","    except:\n","        pass\n","\n","def save(final_result, name=None, few_shot=False, example=format, data=None):\n","    create_dir(dirname)\n","    create_dir(pickle_dir)\n","    \n","    model_name = model_path.split('/')[-1]\n","    inserted_name = \"\" if name is None else \"_\" + name\n","    i = 1\n","    while True:\n","        file_path = f'{dirname}/{model_name}{inserted_name}_{i}.txt'\n","        pickle_path = f'{pickle_dir}/{model_name}{inserted_name}_{i}.json'\n","        try:\n","            with open(file_path, 'r'):\n","                i += 1\n","        except:\n","            with open(file_path, 'w') as file:\n","                file.write(model_name+'\\n')\n","                if few_shot:\n","                    file.write(few_shot + '\\n')\n","                if not isinstance(example, str):\n","                    example = json.dumps(example)\n","                file.write(example + '\\n')\n","                file.write(json.dumps(final_result, indent=4))\n","            if data is None:\n","                print(f\"Warning, {model_name} results data not saving in json, please provide data arg\")\n","            else:\n","                with open(pickle_path, 'w') as file:\n","                    file.write(json.dumps(data, indent=4))\n","            return"]},{"cell_type":"markdown","metadata":{},"source":["### Load the model\n","\n","Login kako bi se mogli ucitati napredniji modeli"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T20:37:30.309337Z","iopub.status.busy":"2024-10-14T20:37:30.309064Z","iopub.status.idle":"2024-10-14T20:37:30.371472Z","shell.execute_reply":"2024-10-14T20:37:30.370436Z","shell.execute_reply.started":"2024-10-14T20:37:30.309314Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"markdown","metadata":{},"source":["Logiranje u huggingiface\n","treba kljuc, njega nabavite na huggingface stranici"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T20:37:30.372904Z","iopub.status.busy":"2024-10-14T20:37:30.372637Z","iopub.status.idle":"2024-10-14T20:37:30.517356Z","shell.execute_reply":"2024-10-14T20:37:30.516413Z","shell.execute_reply.started":"2024-10-14T20:37:30.372881Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","login('insert yours', add_to_git_credential=False, write_permission=True)"]},{"cell_type":"markdown","metadata":{},"source":["BitsAndBytesConfig je novi, to kao kvantizira model pa stane na graficku"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T21:01:50.742300Z","iopub.status.busy":"2024-10-14T21:01:50.741585Z","iopub.status.idle":"2024-10-14T21:04:05.207447Z","shell.execute_reply":"2024-10-14T21:04:05.206653Z","shell.execute_reply.started":"2024-10-14T21:01:50.742265Z"},"trusted":true},"outputs":[],"source":["\n","# model_path = 'google/flan-t5-xxl'\n","# model_path = 'google/flan-t5-xl'\n","# model_path = 'google/flan-t5-large'\n","# model_path = 'mistralai/Mistral-7B-Instruct-v0.2'\n","# model_path = 'mistralai/Mistral-7B-v0.3'\n","# model_path = 'microsoft/phi-2'\n","# model_path = 'microsoft/Phi-3-mini-128k-instruct'\n","# model_path = 'microsoft/Phi-3-mini-4k-instruct'\n","# model_path = '01-ai/Yi-1.5-6B'\n","# model_path = 'netcat420/MFANN3bv0.6'\n","model_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","# model_path = \"meta-llama/Meta-Llama-3-8B\"\n","# model_path = \"allenai/OLMo-7B-Instruct\"\n","# model_path = \"tiiuae/falcon-7b-instruct\"\n","# model_path = \"tiiuae/falcon-7b\"\n","# model_path = 'Intel/neural-chat-7b-v3-1'\n","# model_path = \"google/gemma-1.1-7b-it\"\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","def get_mistral():\n","    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_path,\n","        device_map=\"auto\",\n","        quantization_config=quantization_config,\n","        trust_remote_code=True,\n","    )\n","    return tokenizer, model\n","\n","def get_llama():\n","    tokenizer = AutoTokenizer.from_pretrained(model_path)\n","    model_4bit = AutoModelForCausalLM.from_pretrained(\n","        model_path,\n","#         \"SweatyCrayfish/llama-3-8b-quantized\", \n","#         load_in_4bit=True, \n","#         torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        quantization_config=quantization_config,\n","    )\n","    return tokenizer, model_4bit\n","\n","tokenizer, model = get_mistral()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset\n","\n","- Skinuti s [linka](https://drive.google.com/drive/u/0/folders/1kiFXp5fqpf8--NQJJAlBIBpfSaXTk1UY)\n","\n","- Staviti u folder `/data`, ako na Kaggleu, onda napraviti svoj dataset te ga dodati pod input"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T21:04:05.217154Z","iopub.status.busy":"2024-10-14T21:04:05.216602Z","iopub.status.idle":"2024-10-14T21:04:05.254577Z","shell.execute_reply":"2024-10-14T21:04:05.253715Z","shell.execute_reply.started":"2024-10-14T21:04:05.217122Z"},"trusted":true},"outputs":[],"source":["# few_shot_examples = list(np.load(\"./{dataset_path}/data/demonstration.npy\",allow_pickle=True))\n","data_path = '/kaggle/input/brainteaser/data'\n","sentence_data_path = f\"{data_path}/SP-train.npy\"\n","wordplay_data_list = f\"{data_path}/WP-train.npy\"\n","sentence_data_list = list(np.load(sentence_data_path,allow_pickle=True))\n","wordplay_data_list = list(np.load(wordplay_data_list,allow_pickle=True))\n","\n","test_data_list = sentence_data_list + wordplay_data_list\n","print(f\"Dataset length {len(test_data_list)}\")"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T21:04:05.257402Z","iopub.status.busy":"2024-10-14T21:04:05.256688Z","iopub.status.idle":"2024-10-14T21:04:05.262990Z","shell.execute_reply":"2024-10-14T21:04:05.262120Z","shell.execute_reply.started":"2024-10-14T21:04:05.257368Z"},"trusted":true},"outputs":[],"source":["def get_format(letters, demonstration):\n","    newline = '\\n'\n","    format = f\"\"\"Question: {\"{}\"}\n","\n","Choices:\n","{''.join('(' + x + ') {}' + newline for x in letters)}\"\"\"\n","    if demonstration is not None:\n","        format = demonstration + \"\\n\\n\" + format\n","    format += \"\\nAnswer:(\"\n","    return format\n","\n","def get_prompt(sample: dict, *args, **kwargs):\n","    format = get_format(*args, **kwargs)\n","    sample_demo = format.format(\n","        sample['question'], *sample['choice_list'])\n","    return sample_demo"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T21:04:05.264238Z","iopub.status.busy":"2024-10-14T21:04:05.263969Z","iopub.status.idle":"2024-10-14T21:04:05.273178Z","shell.execute_reply":"2024-10-14T21:04:05.272309Z","shell.execute_reply.started":"2024-10-14T21:04:05.264216Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, samples: list, letters=None, demonstration=None):\n","    if letters is None:\n","        letters = [\"A\", \"B\", \"C\", \"D\"]\n","    for sample in tqdm(samples):\n","        text = get_prompt(sample, letters=letters, demonstration=demonstration)\n","        inputs = tokenizer.encode(text, return_tensors=\"pt\", return_attention_mask=False).to(model.device)\n","        with torch.no_grad():\n","            results = model(inputs)\n","        probs = torch.nn.functional.softmax(results.logits.squeeze()[-1], dim=-1)\n","        model_answer = tokenizer.decode(probs.argmax())\n","        model_answer_prob= float(probs.max())\n","        model_correct = model_answer == letters[sample[\"label\"]]\n","        sample['model_probs'] = probs\n","        sample['model_answer'] = model_answer\n","        sample['model_answer_prob'] = model_answer_prob\n","        sample['model_correct'] = model_correct"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T21:04:05.274565Z","iopub.status.busy":"2024-10-14T21:04:05.274278Z","iopub.status.idle":"2024-10-14T21:09:32.256722Z","shell.execute_reply":"2024-10-14T21:09:32.255692Z","shell.execute_reply.started":"2024-10-14T21:04:05.274533Z"},"trusted":true},"outputs":[],"source":["letters = [\"A\", \"B\", \"C\", \"D\"]\n","demonstration = \"The following question is a brainteaser.\"\n","print(get_prompt(test_data_list[0], letters=letters, demonstration=demonstration))\n","evaluate(model, test_data_list, letters=letters, demonstration=demonstration)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T21:10:46.254369Z","iopub.status.busy":"2024-10-14T21:10:46.253989Z","iopub.status.idle":"2024-10-14T21:10:46.541328Z","shell.execute_reply":"2024-10-14T21:10:46.540406Z","shell.execute_reply.started":"2024-10-14T21:10:46.254338Z"},"trusted":true},"outputs":[],"source":["samples = test_data_list\n","y_true = [sample[\"model_answer\"] for sample in samples]\n","pos_label = [letters[sample[\"label\"]] for sample in samples]\n","y_prob = [float(sample[\"model_answer_prob\"]) for sample in samples]\n","\n","\n","model_name = model.name_or_path.split('/')[-1]\n","precision, recall, thresholds = precision_recall_curve(y_true, y_prob, pos_label=pos_label)\n","\n","plt.fill_between(recall, precision)\n","plt.ylabel(\"Precision\")\n","plt.xlabel(\"Recall\")\n","plt.title(f\"Precision-Recall curve {model_name}\");\n","\n","# plt.fill_between(thresholds, precision[:-1])\n","# plt.ylabel(\"Precision\")\n","# plt.xlabel(\"Tresholds\")\n","# plt.xlim(0,1)\n","# plt.title(f\"Treshold-precision curve {model_name}\");"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4946147,"sourceId":8329940,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
