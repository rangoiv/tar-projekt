{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Brain teaser\n","\n","[Original Github REPO](https://github.com/1171-jpg/BrainTeaser)\n","\n","[Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:46:55.023935Z","iopub.status.busy":"2024-05-27T19:46:55.022955Z","iopub.status.idle":"2024-05-27T19:47:28.606417Z","shell.execute_reply":"2024-05-27T19:47:28.605436Z","shell.execute_reply.started":"2024-05-27T19:46:55.023890Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cubinlinker, which is not installed.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires ptxcompiler, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.8.2 requires keras-core, which is not installed.\n","keras-nlp 0.9.3 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\n","cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\n","jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q -U langchain transformers bitsandbytes accelerate"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:28.608575Z","iopub.status.busy":"2024-05-27T19:47:28.608277Z","iopub.status.idle":"2024-05-27T19:47:46.050067Z","shell.execute_reply":"2024-05-27T19:47:46.049306Z","shell.execute_reply.started":"2024-05-27T19:47:28.608544Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-27 19:47:36.045744: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-27 19:47:36.045842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-27 19:47:36.168097: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import numpy as np\n","import json\n","from datasets import load_dataset\n","from random import shuffle\n","import random\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","\n","import torch\n","from torch.nn.functional import normalize\n","from transformers import AutoModel, AutoTokenizer\n","\n","from tqdm.auto import tqdm\n","import numpy as np\n","import os\n","from transformers import StoppingCriteriaList\n","\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","import gc"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.051631Z","iopub.status.busy":"2024-05-27T19:47:46.051090Z","iopub.status.idle":"2024-05-27T19:47:46.063454Z","shell.execute_reply":"2024-05-27T19:47:46.061981Z","shell.execute_reply.started":"2024-05-27T19:47:46.051604Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(['A', 'B', 'C', 'D'], 4)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Ako imamo vise ponudenih odgovora od 4, da postupak bude automatski u svim funkcijama\n","letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'][:4]\n","letters, len(letters)"]},{"cell_type":"markdown","metadata":{},"source":["## Metrike\n","\n","Preuzeto direktno s njihovog repoa"]},{"cell_type":"code","execution_count":9,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2024-05-27T19:47:46.067736Z","iopub.status.busy":"2024-05-27T19:47:46.067398Z","iopub.status.idle":"2024-05-27T19:47:46.086849Z","shell.execute_reply":"2024-05-27T19:47:46.086052Z","shell.execute_reply.started":"2024-05-27T19:47:46.067695Z"},"trusted":true},"outputs":[],"source":["import json\n","from tqdm import tqdm\n","import torch\n","import logging\n","import argparse\n","import numpy as np\n","\n","def getResultdata(result_data):\n","    choice_to_index = {letters[i]: i for i in range(len(letters))}\n","    choice_to_index[None] = len(letters)\n","\n","    word_play = {}\n","    reverse_play = {}\n","    for item in result_data:\n","        item_type = item['id'].split(\"-\")[0]\n","        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n","        if item_type == 'WP':\n","            if item_id not in word_play:\n","                word_play[item_id] = [0,0,0]\n","        else:\n","            if item_id not in reverse_play:\n","                reverse_play[item_id] = [0,0,0]\n","\n","    for item in result_data:\n","        item_type = item['id'].split(\"-\")[0]\n","        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n","        ad_type = 0\n","        if 'SR' in item['id']:\n","            ad_type = 1\n","        elif 'CR' in item['id']:\n","            ad_type = 2\n","        else:\n","            ad_type = 0\n","\n","        if item_type == 'WP':\n","            if choice_to_index[item['predict']] == item['label']:\n","                word_play[item_id][ad_type] = 1\n","        else:\n","            if choice_to_index[item['predict']] == item['label']:\n","                reverse_play[item_id][ad_type] = 1\n","                \n","    return word_play,reverse_play\n","\n","\n","def getMetric(data_list):\n","    data_list = np.array(data_list)\n","    overall_accuracy = np.sum(data_list)/3/len(data_list)\n","    original_accuracy = np.sum(data_list,axis = 0)[0]/len(data_list)\n","    semantic_accuracy = np.sum(data_list,axis = 0)[1]/len(data_list)\n","    context_accuracy = np.sum(data_list,axis = 0)[2]/len(data_list)\n","    ori_sema = np.sum([1 if item[0]==1 and item[1] == 1 else 0 for item in data_list])/len(data_list)\n","    ori_sema_cont = np.sum([1 if item[0]==1 and item[1] == 1 and item[2] == 1  else 0 for item in data_list])/len(data_list)\n","    \n","    print(\"over_all accuracy {}\".format(overall_accuracy))\n","    print(\"single_original_accuracy {}\".format(original_accuracy))\n","    print(\"single_semantic_accuracy {}\".format(semantic_accuracy))\n","    print(\"single_context_accuracy {}\".format(context_accuracy))\n","    print(\"sr_accuracy {}\".format(ori_sema))\n","    print(\"cr_accuracy {}\".format(ori_sema_cont))\n","\n","    return {'over_all accuracy':overall_accuracy,'original_accuracy':original_accuracy,'semantic_accuracy':semantic_accuracy,'context_accuracy':context_accuracy,'ori_sema':ori_sema,'ori_sema_cont':ori_sema_cont}\n","\n","\n","def getSeperateResult(word_play,reverse_thinking):\n","    final_result = {}\n","    word_data_list = []\n","    word_data_list = list(word_play.values())\n","    print('#########Wordplay##########')\n","    final_result['wordplay'] = getMetric(word_data_list)\n","    \n","    reverse_data_list = []\n","    for item in reverse_thinking.values():\n","        reverse_data_list.append(item)\n","    print('#########Sentence##########')   \n","    final_result['sentence'] = getMetric(reverse_data_list)  \n","    \n","    \n","    all_data = word_data_list + reverse_data_list\n","    print('#########All data##########') \n","    final_result['all'] = getMetric(all_data) \n","    \n","    return final_result"]},{"cell_type":"markdown","metadata":{},"source":["### Spremanje datoteka\n","\n","Automatski dodaje +1 na naziv ako vec postoji takva datoteka\n","\n","Uzima format model_name + name + redni broj za datoteku\n","\n","Unutra pise prvi testni primjer (example) i rezultate"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.087966Z","iopub.status.busy":"2024-05-27T19:47:46.087733Z","iopub.status.idle":"2024-05-27T19:47:46.100371Z","shell.execute_reply":"2024-05-27T19:47:46.099578Z","shell.execute_reply.started":"2024-05-27T19:47:46.087945Z"},"trusted":true},"outputs":[],"source":["def save(final_result, name=None, few_shot=False, example=format):\n","    try:\n","        os.mkdir('results')\n","    except:\n","        pass\n","    model_name = model_path.split('/')[-1]\n","    inserted_name = \"\" if name is None else \"_\" + name\n","    i = 1\n","    while True:\n","        file_path = f'results/{model_name}{inserted_name}_{i}.txt'\n","        try:\n","            with open(file_path, 'r'):\n","                i += 1\n","        except:\n","            with open(file_path, 'w') as file:\n","                file.write(model_name+'\\n')\n","                if few_shot:\n","                    file.write(few_shot + '\\n')\n","                if not isinstance(example, str):\n","                    example = json.dumps(example)\n","                file.write(example + '\\n')\n","                file.write(json.dumps(final_result, indent=4))\n","                return"]},{"cell_type":"markdown","metadata":{},"source":["### Load the model\n","\n","Login kako bi se mogli ucitati napredniji modeli"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.101858Z","iopub.status.busy":"2024-05-27T19:47:46.101447Z","iopub.status.idle":"2024-05-27T19:47:46.137531Z","shell.execute_reply":"2024-05-27T19:47:46.136701Z","shell.execute_reply.started":"2024-05-27T19:47:46.101826Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"markdown","metadata":{},"source":["Logiranje u huggingiface\n","treba kljuc, njega nabavite na huggingface stranici"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.139574Z","iopub.status.busy":"2024-05-27T19:47:46.138872Z","iopub.status.idle":"2024-05-27T19:47:46.239439Z","shell.execute_reply":"2024-05-27T19:47:46.238563Z","shell.execute_reply.started":"2024-05-27T19:47:46.139540Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login('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', add_to_git_credential=False, write_permission=True)"]},{"cell_type":"markdown","metadata":{},"source":["BitsAndBytesConfig je novi, to kao kvantizira model pa stane na graficku"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.240935Z","iopub.status.busy":"2024-05-27T19:47:46.240673Z","iopub.status.idle":"2024-05-27T19:47:46.244491Z","shell.execute_reply":"2024-05-27T19:47:46.243627Z","shell.execute_reply.started":"2024-05-27T19:47:46.240913Z"},"trusted":true},"outputs":[],"source":["# !pip install ai2-olmo"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.245841Z","iopub.status.busy":"2024-05-27T19:47:46.245557Z","iopub.status.idle":"2024-05-27T19:51:24.169756Z","shell.execute_reply":"2024-05-27T19:51:24.168879Z","shell.execute_reply.started":"2024-05-27T19:47:46.245817Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6ca5a9ee4154654af5e6755b2b94aa3","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f55b3096eac4f369f2333470c184fcb","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2670ee86bbce45e98abd2994cf3ee006","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec0374299dfa41c1bd3c2e7d2fca4d7b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5705588dca241e28bd348d6576f1dfe","version_major":2,"version_minor":0},"text/plain":["configuration_falcon.py:   0%|          | 0.00/7.16k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n","- configuration_falcon.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b727e5ffd404755accc7ec5e1c0bfc6","version_major":2,"version_minor":0},"text/plain":["modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n","- modeling_falcon.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e220864a26404f4fb1cd3b48faa8b9c2","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a84345182e1649acace6b8e7e4767176","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b596f5c4cabe4ea7ac5b510327b43db3","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd033ca80074408ead6135c84aa5d7c2","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8c352273e8f4d10a641f25cab19e26d","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1a3d7917603453384240aef56cf7a98","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["\n","# model_path = 'google/flan-t5-xxl'\n","# model_path = 'google/flan-t5-xl'\n","# model_path = 'google/flan-t5-large'\n","# model_path = 'mistralai/Mistral-7B-Instruct-v0.2'\n","# model_path = 'mistralai/Mistral-7B-v0.3'\n","# model_path = 'microsoft/phi-2'\n","# model_path = 'microsoft/Phi-3-mini-128k-instruct'\n","# model_path = 'microsoft/Phi-3-mini-4k-instruct'\n","# model_path = '01-ai/Yi-1.5-6B'\n","# model_path = 'netcat420/MFANN3bv0.6'\n","# model_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","# model_path = \"meta-llama/Meta-Llama-3-8B\"\n","# model_path = \"allenai/OLMo-7B-Instruct\"\n","# model_path = \"tiiuae/falcon-7b-instruct\"\n","model_path = \"tiiuae/falcon-7b\"\n","# model_path = 'Intel/neural-chat-7b-v3-1'\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","def get_mistral():\n","    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_path,\n","        device_map=\"auto\",\n","        quantization_config=quantization_config,\n","        trust_remote_code=True,\n","    )\n","    return tokenizer, model\n","\n","def get_llama():\n","    tokenizer = AutoTokenizer.from_pretrained(model_path)\n","    model_4bit = AutoModelForCausalLM.from_pretrained(\n","        model_path,\n","#         \"SweatyCrayfish/llama-3-8b-quantized\", \n","#         load_in_4bit=True, \n","#         torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        quantization_config=quantization_config,\n","    )\n","    return tokenizer, model_4bit\n","\n","tokenizer, model = get_mistral()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset\n","\n","- Skinuti s [linka](https://drive.google.com/drive/u/0/folders/1kiFXp5fqpf8--NQJJAlBIBpfSaXTk1UY)\n","\n","- Staviti u folder `/data`, ako na Kaggleu, onda napraviti svoj dataset te ga dodati pod input"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.173306Z","iopub.status.busy":"2024-05-27T19:51:24.173008Z","iopub.status.idle":"2024-05-27T19:51:24.197324Z","shell.execute_reply":"2024-05-27T19:51:24.196471Z","shell.execute_reply.started":"2024-05-27T19:51:24.173280Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset length 903\n"]}],"source":["# few_shot_examples = list(np.load(\"./{dataset_path}/data/demonstration.npy\",allow_pickle=True))\n","data_path = '/kaggle/input/brainteaser/data'\n","sentence_data_path = f\"{data_path}/SP-train.npy\"\n","wordplay_data_list = f\"{data_path}/WP-train.npy\"\n","sentence_data_list = list(np.load(sentence_data_path,allow_pickle=True))\n","wordplay_data_list = list(np.load(wordplay_data_list,allow_pickle=True))\n","\n","test_data_list = sentence_data_list + wordplay_data_list\n","print(f\"Dataset length {len(test_data_list)}\")"]},{"cell_type":"markdown","metadata":{},"source":["Format za mystral, za ostale modele maknuti linije `<s>[INST]`"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.198506Z","iopub.status.busy":"2024-05-27T19:51:24.198251Z","iopub.status.idle":"2024-05-27T19:51:24.254936Z","shell.execute_reply":"2024-05-27T19:51:24.254080Z","shell.execute_reply.started":"2024-05-27T19:51:24.198483Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"]},{"name":"stdout","output_type":"stream","text":["<|im_start|>system\n","Primjer<|im_end|>\n","<|im_start|>user\n","Question: {}\n","Choice:\n","(A) {}\n","(B) {}\n","(C) {}\n","(D) {}\n","<|im_end|>\n","<|im_start|>assistant\n","Answer:(\n"]}],"source":["format = \"\"\n","def get_format():\n","    global format\n","    newline = '\\n'\n","    format = f\"\"\"Question: {\"{}\"}\n","Choice:\n","{''.join('(' + x + ') {}' + newline for x in letters)}\"\"\"\n","    return format\n","\n","def get_llama_format(demonstration=None):\n","    global tokenizer, format\n","    messages = []\n","    if demonstration is not None:\n","        messages.append({\"role\": \"system\", \"content\": demonstration})\n","    messages.append({\"role\": \"user\", \"content\": get_format()})\n","    messages.append({\"role\": \"assistant\", \"content\": \"Answer:(\"})\n","    try:\n","        format = tokenizer.apply_chat_template(messages, tokenize=False)\n","    except Exception:\n","        # When using mistral model, roles in messages must alternate, this way it works without errors\n","        messages[1][\"content\"] = demonstration + \"\\n\\n\" + messages[1][\"content\"]\n","        format = tokenizer.apply_chat_template(messages[1:], tokenize=False)\n","    # remove \"<|eot_id|>\" from the end\n","    format = format[:format.index(\"Answer:(\")+8]\n","\n","def get_appended_format(demonstration=None):\n","    global format\n","    format = get_format()\n","    if demonstration is not None:\n","        format = demonstration + \"\\n\\n\" + format\n","    format += \"\\nAnswer:(\"\n","\n","get_llama_format(\"Primjer\")\n","print(format)\n","get_appended_format()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.256336Z","iopub.status.busy":"2024-05-27T19:51:24.255882Z","iopub.status.idle":"2024-05-27T19:51:24.261244Z","shell.execute_reply":"2024-05-27T19:51:24.260375Z","shell.execute_reply.started":"2024-05-27T19:51:24.256312Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["good_responses ['A)', 'B)', 'C)', 'D)']\n"]}],"source":["def get_single_demo(sample):\n","    global format\n","    sample_demo = format.format(\n","        sample['question'], *sample['choice_list'])\n","    return sample_demo\n","\n","good_responses = [f'{x})' for x in letters]\n","print(\"good_responses\", good_responses)"]},{"cell_type":"markdown","metadata":{},"source":["## Generiranje dataseta\n","\n","### Pomocne funkcije"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.262641Z","iopub.status.busy":"2024-05-27T19:51:24.262352Z","iopub.status.idle":"2024-05-27T19:51:24.270592Z","shell.execute_reply":"2024-05-27T19:51:24.269719Z","shell.execute_reply.started":"2024-05-27T19:51:24.262609Z"},"trusted":true},"outputs":[],"source":["def set_predictions(data_list):\n","    \"\"\"Uzima response i parsira ga tako da pod predict stavi slovo koje je napisano\"\"\"\n","    for index,item in enumerate(data_list):\n","        item['predict'] = None\n","        for x in letters:\n","            if (f'{x})') in item['response']:\n","                item['predict'] = x\n","\n","        if item['predict'] is None:\n","            print(index)\n","\n","def custom_stopping_criteria(input_ids: torch.LongTensor, score: torch.FloatTensor, **kwargs) -> bool:\n","    \"\"\"\n","    Funkcija kako bi se dinamicki prepoznalo kad treba prestati generirati tekst:\n","    ne nakon fiksnog broja tokena, vec kad model napise rjesenje. Najcesce\n","    ce to ipak biti medu prva dva tokena\n","    \"\"\"\n","    decoded = tokenizer.decode(input_ids[0][-3:])\n","    for good_response in good_responses:\n","        if good_response in decoded:\n","            return True\n","    return False\n","\n","stopping_criteria = StoppingCriteriaList([custom_stopping_criteria])"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.272112Z","iopub.status.busy":"2024-05-27T19:51:24.271754Z","iopub.status.idle":"2024-05-27T19:51:24.284875Z","shell.execute_reply":"2024-05-27T19:51:24.283997Z","shell.execute_reply.started":"2024-05-27T19:51:24.272057Z"},"trusted":true},"outputs":[],"source":["def generate(samples, tokens=10, all_tokens=True, few_shot=False):\n","    global model\n","    for sample in tqdm(samples):\n","        if few_shot:\n","            text = demonstration + get_single_demo(sample)\n","        else:\n","            text = get_single_demo(sample)\n","        inputs = tokenizer.encode(text, return_tensors=\"pt\", return_attention_mask=False).to(device)\n","        original_tokens = len(inputs[0])\n","        outputs = model.generate(\n","            inputs,\n","            pad_token_id=tokenizer.eos_token_id,\n","            do_sample = False,\n","            max_new_tokens=tokens,\n","            stopping_criteria=stopping_criteria\n","        )\n","        outputs = outputs[0][0 if all_tokens else original_tokens:]\n","        sample['response'] = tokenizer.decode(outputs)\n","    set_predictions(samples)"]},{"cell_type":"markdown","metadata":{},"source":["## Testiranje"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.286265Z","iopub.status.busy":"2024-05-27T19:51:24.285893Z","iopub.status.idle":"2024-05-27T19:51:30.035653Z","shell.execute_reply":"2024-05-27T19:51:30.034799Z","shell.execute_reply.started":"2024-05-27T19:51:24.286230Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:05<00:00,  1.74it/s]\n"]}],"source":["get_llama_format()\n","generate(test_data_list[:10], tokens=1000, all_tokens=False, few_shot=False)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:30.037236Z","iopub.status.busy":"2024-05-27T19:51:30.036902Z","iopub.status.idle":"2024-05-27T19:51:30.041949Z","shell.execute_reply":"2024-05-27T19:51:30.041060Z","shell.execute_reply.started":"2024-05-27T19:51:30.037175Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","> A)\n","\n","> A)\n","\n","> A)\n","\n","> A)\n","\n","> A)\n","\n","> A)\n","\n","> A)\n","\n","> A)\n","\n","> A)\n","\n","> A)\n"]}],"source":["for sample in test_data_list[:10]:\n","    print(\"\\n>\", sample['response'])"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:30.043451Z","iopub.status.busy":"2024-05-27T19:51:30.043152Z","iopub.status.idle":"2024-05-27T19:51:33.450799Z","shell.execute_reply":"2024-05-27T19:51:33.449822Z","shell.execute_reply.started":"2024-05-27T19:51:30.043426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<|im_start|>user\n","Question: The six daughters of Mr. and Mrs. Mustard each have one brother. However, the family only consists of nine people; how is that possible?\n","Choice:\n","(A) Some brothers were not loved by family and moved away.\n","(B) Some daughters get married and have their own family.\n","(C) Each daughter shares the same brother.\n","(D) None of above.\n","<|im_end|>\n","<|im_start|>assistant\n","Answer:(A) Some brothers were not loved by family and moved away.\n","<|im_end|>\n","<|im_start|>assistant\n","Answer:(B) Some daughters get married and have their own family.\n","<|im_end\n"]}],"source":["get_llama_format()\n","text = get_single_demo(test_data_list[1])\n","inputs = tokenizer.encode(text, return_tensors=\"pt\", return_attention_mask=False).to(device)\n","outputs = model.generate(\n","    inputs,\n","    pad_token_id=tokenizer.eos_token_id,\n","    do_sample = False,\n","    max_new_tokens=50,\n",")\n","print(tokenizer.decode(outputs[0]))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.452396Z","iopub.status.busy":"2024-05-27T19:51:33.452054Z","iopub.status.idle":"2024-05-27T19:51:33.458756Z","shell.execute_reply":"2024-05-27T19:51:33.457826Z","shell.execute_reply.started":"2024-05-27T19:51:33.452352Z"},"trusted":true},"outputs":[],"source":["# generate(test_data_list, tokens=20, all_tokens=False, few_shot=False)\n","\n","# word_play,sentence_play = getResultdata(test_data_list)\n","# # word_play,sentence_play = getResultdata(test_data_list)\n","# final_result = getSeperateResult(word_play, sentence_play)\n","\n","# save(final_result, name=\"with-instruction\", example=get_single_demo(test_data_list[0]))"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.460333Z","iopub.status.busy":"2024-05-27T19:51:33.459840Z","iopub.status.idle":"2024-05-27T19:51:33.467208Z","shell.execute_reply":"2024-05-27T19:51:33.466338Z","shell.execute_reply.started":"2024-05-27T19:51:33.460282Z"},"trusted":true},"outputs":[],"source":["demonstration1 = \"Please pick the best choice for the brain teaser. Each brain teaser has only one possible solution including the choice none of above, answer should only provide the choice:\"\n","demonstration2 = \"The following question is a brainteaser. One choice is correct, other choices are semanticaly derived from the question.\"\n","demonstration3 = \"The following question is a brainteaser.\"\n","demonstration4 = \"The following question is a brainteaser. One choice is correct, other choices are semanticaly derived from the question. Sometimes none of the above is correct.\"\n","demonstration5 = \"The following question is a brainteaser. Sometimes none of the above is correct.\""]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-05-24T12:31:13.723172Z","iopub.status.busy":"2024-05-24T12:31:13.722785Z","iopub.status.idle":"2024-05-24T12:31:14.068435Z","shell.execute_reply":"2024-05-24T12:31:14.067422Z","shell.execute_reply.started":"2024-05-24T12:31:13.723141Z"}},"source":["\n","\n","- `The following question is a brainteaser. One choice is correct, other choices are semanticaly derived from the question. Sometimes none of the above is correct.`\n","\n","- `The following question is a brainteaser. One choice is correct, other choices are semanticaly derived from the question.`\n","\n","- `The following question is a brainteaser.` (less informative, helpful) \n","\n","- `Please pick the best choice for the brain teaser. Each brain teaser has only one possible solution including the choice none of above, answer should only provide the choice:` (Original, more informative, helpful) "]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.468688Z","iopub.status.busy":"2024-05-27T19:51:33.468424Z","iopub.status.idle":"2024-05-27T19:51:33.477359Z","shell.execute_reply":"2024-05-27T19:51:33.476433Z","shell.execute_reply.started":"2024-05-27T19:51:33.468664Z"},"trusted":true},"outputs":[],"source":["def generate_and_save(test_data_list, name=\"normal\"):\n","    generate(test_data_list, tokens=20, all_tokens=False, few_shot=False)\n","\n","    word_play,sentence_play = getResultdata(test_data_list)\n","    # word_play,sentence_play = getResultdata(test_data_list)\n","    final_result = getSeperateResult(word_play, sentence_play)\n","\n","    save(final_result, name=name, example=get_single_demo(test_data_list[0]))"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.480658Z","iopub.status.busy":"2024-05-27T19:51:33.480402Z","iopub.status.idle":"2024-05-27T19:51:33.486346Z","shell.execute_reply":"2024-05-27T19:51:33.485593Z","shell.execute_reply.started":"2024-05-27T19:51:33.480635Z"},"trusted":true},"outputs":[],"source":["def generate_with_demonstration(demonstration=None,test_data_list=test_data_list, name=\"with-instruction\", llama_format=False):\n","    if llama_format:\n","        get_llama_format(demonstration)\n","    else:\n","        get_appended_format(demonstration)\n","    generate_and_save(test_data_list, name=name)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.487950Z","iopub.status.busy":"2024-05-27T19:51:33.487596Z","iopub.status.idle":"2024-05-27T19:51:33.500682Z","shell.execute_reply":"2024-05-27T19:51:33.499846Z","shell.execute_reply.started":"2024-05-27T19:51:33.487910Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<|im_start|>system\n","jalo<|im_end|>\n","<|im_start|>user\n","Question: {}\n","Choice:\n","(A) {}\n","(B) {}\n","(C) {}\n","(D) {}\n","<|im_end|>\n","<|im_start|>assistant\n","Answer:(\n"]}],"source":["get_llama_format(\"jalo\")\n","print(format[:format.index(\"Answer:(\")+8])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["This question is a brainteaser.\n","\n","Question: {}\n","Choice:\n","(A) {}\n","(B) {}\n","(C) {}\n","(D) {}\n","\n","Answer:("]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.501923Z","iopub.status.busy":"2024-05-27T19:51:33.501691Z","iopub.status.idle":"2024-05-27T19:51:33.509317Z","shell.execute_reply":"2024-05-27T19:51:33.508499Z","shell.execute_reply.started":"2024-05-27T19:51:33.501902Z"},"trusted":true},"outputs":[],"source":["# save({}, name=\"normal\", example=get_single_demo(test_data_list[0]))"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.510516Z","iopub.status.busy":"2024-05-27T19:51:33.510253Z","iopub.status.idle":"2024-05-27T19:51:33.518497Z","shell.execute_reply":"2024-05-27T19:51:33.517721Z","shell.execute_reply.started":"2024-05-27T19:51:33.510493Z"},"trusted":true},"outputs":[],"source":["# generate_with_demonstration(test_data_list[:10]+ test_data_list[-10:], name=\"normal\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.519856Z","iopub.status.busy":"2024-05-27T19:51:33.519387Z","iopub.status.idle":"2024-05-27T19:51:33.528496Z","shell.execute_reply":"2024-05-27T19:51:33.527743Z","shell.execute_reply.started":"2024-05-27T19:51:33.519831Z"},"trusted":true},"outputs":[],"source":["# generate_with_demonstration(name=\"normal\")\n","# generate_with_demonstration(demonstration1, name=\"dem1\")\n","# generate_with_demonstration(demonstration3, name=\"dem3\")\n","# generate_with_demonstration(demonstration2, name=\"dem2\")\n","# generate_with_demonstration(demonstration4, name=\"dem4\")\n","\n","# generate_with_demonstration(name=\"normal-spec\")\n","# generate_with_demonstration(demonstration1, name=\"dem1-spec\", llama_format=True)\n","# generate_with_demonstration(demonstration3, name=\"dem3-spec\", llama_format=True)\n","# generate_with_demonstration(demonstration2, name=\"dem2-spec\", llama_format=True)\n","# generate_with_demonstration(demonstration4, name=\"dem4-spec\", llama_format=True)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.529583Z","iopub.status.busy":"2024-05-27T19:51:33.529356Z","iopub.status.idle":"2024-05-27T19:51:33.540842Z","shell.execute_reply":"2024-05-27T19:51:33.539968Z","shell.execute_reply.started":"2024-05-27T19:51:33.529562Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'id': 'SP-0',\n"," 'question': 'Mr. and Mrs. Mustard have six daughters and each daughter has one brother. But there are only 9 people in the family, how is that possible?',\n"," 'answer': 'Each daughter shares the same brother.',\n"," 'distractor1': 'Some daughters get married and have their own family.',\n"," 'distractor2': 'Some brothers were not loved by family and moved away.',\n"," 'distractor(unsure)': 'None of above.',\n"," 'label': 1,\n"," 'choice_list': ['Some daughters get married and have their own family.',\n","  'Each daughter shares the same brother.',\n","  'Some brothers were not loved by family and moved away.',\n","  'None of above.'],\n"," 'choice_order': [1, 0, 2, 3],\n"," 'response': 'A)',\n"," 'predict': 'A'}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["test_data_list[0]"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.542311Z","iopub.status.busy":"2024-05-27T19:51:33.541963Z","iopub.status.idle":"2024-05-27T19:51:33.548773Z","shell.execute_reply":"2024-05-27T19:51:33.547997Z","shell.execute_reply.started":"2024-05-27T19:51:33.542279Z"},"trusted":true},"outputs":[],"source":["model = None\n","def run_with_model(model_path_tmp):\n","    global tokenizer, model, model_path\n","    del model\n","    model = None\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    model_path = model_path_tmp\n","    print(f\"Loading {model_path}\")\n","    tokenizer, model = get_mistral()\n","\n","    print(f\"Running {model_path}\")\n","    generate_with_demonstration(demonstration5, name=\"dem5\")\n","    if 'instruct' in model_path or 'Instruct' in model_path:\n","        generate_with_demonstration(demonstration5, name=\"dem5-spec\", llama_format=True)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.553640Z","iopub.status.busy":"2024-05-27T19:51:33.552895Z","iopub.status.idle":"2024-05-27T20:28:00.362932Z","shell.execute_reply":"2024-05-27T20:28:00.361001Z","shell.execute_reply.started":"2024-05-27T19:51:33.553614Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading meta-llama/Meta-Llama-3-8B\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d23e48d1d1b4469b916268bcd1e7d9c","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f519317aea934cd5ac12f72cb1a4d810","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c8a8ed7ccb649a0b1008be1e2d90f8c","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e5388fc4d674c94b1208f54d5cbf25e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3df9f614f754919b65a02e39ab47c1d","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43007290689e43c9ba5f46423c9c6b2d","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e760858f6f6f49a2b2848c4e82e233d7","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73a5b29588584f34a042328dd7dee27a","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab9b752c7b1446ffbe2c6b946ff28ad5","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1a50c579e2d453abbc868d31c919529","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2158f24986c54e9a808817d496b83903","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2368ca81408430690562fefc36edc6a","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Running meta-llama/Meta-Llama-3-8B\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/903 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n","100%|██████████| 903/903 [06:54<00:00,  2.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["#########Wordplay##########\n","over_all accuracy 0.15151515151515152\n","single_original_accuracy 0.12878787878787878\n","single_semantic_accuracy 0.13636363636363635\n","single_context_accuracy 0.1893939393939394\n","sr_accuracy 0.045454545454545456\n","cr_accuracy 0.007575757575757576\n","#########Sentence##########\n","over_all accuracy 0.25641025641025644\n","single_original_accuracy 0.28994082840236685\n","single_semantic_accuracy 0.2485207100591716\n","single_context_accuracy 0.23076923076923078\n","sr_accuracy 0.1952662721893491\n","cr_accuracy 0.10650887573964497\n","#########All data##########\n","over_all accuracy 0.21040974529346623\n","single_original_accuracy 0.21926910299003322\n","single_semantic_accuracy 0.19933554817275748\n","single_context_accuracy 0.21262458471760798\n","sr_accuracy 0.12956810631229235\n","cr_accuracy 0.06312292358803986\n","Loading tiiuae/falcon-7b-instruct\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c271856f57e44d086d47734c7f35a83","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44d267469fe840a8b6f8e820fa2171f0","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf21b35eba4140f0b087090d13de7685","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd821e99b6ab4d7a91faab86ca820aa7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"824356be36f44400b767ae54d1e39cfa","version_major":2,"version_minor":0},"text/plain":["configuration_falcon.py:   0%|          | 0.00/7.16k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n","- configuration_falcon.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"484efbabeb0a4ad480bf7899da7a27c8","version_major":2,"version_minor":0},"text/plain":["modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n","- modeling_falcon.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81dafeea22aa47fd8c72628a0ab7154b","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e6a300d582c46c0b13feb3cc208a7ec","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5668d5a074d6403f8157067a534c48ef","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8269e7ccd740420f870cff61fcb676e7","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d08b35d57a234f2d824d2b0956057b39","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a411cc200ac84cbb90d5294ae3b956e7","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Running tiiuae/falcon-7b-instruct\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 903/903 [07:08<00:00,  2.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["#########Wordplay##########\n","over_all accuracy 0.3484848484848485\n","single_original_accuracy 0.3333333333333333\n","single_semantic_accuracy 0.3484848484848485\n","single_context_accuracy 0.36363636363636365\n","sr_accuracy 0.12121212121212122\n","cr_accuracy 0.03787878787878788\n","#########Sentence##########\n","over_all accuracy 0.30177514792899407\n","single_original_accuracy 0.3431952662721893\n","single_semantic_accuracy 0.2781065088757396\n","single_context_accuracy 0.28402366863905326\n","sr_accuracy 0.10059171597633136\n","cr_accuracy 0.03550295857988166\n","#########All data##########\n","over_all accuracy 0.3222591362126246\n","single_original_accuracy 0.3388704318936877\n","single_semantic_accuracy 0.3089700996677741\n","single_context_accuracy 0.31893687707641194\n","sr_accuracy 0.10963455149501661\n","cr_accuracy 0.036544850498338874\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 903/903 [08:18<00:00,  1.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["#########Wordplay##########\n","over_all accuracy 0.34595959595959597\n","single_original_accuracy 0.3181818181818182\n","single_semantic_accuracy 0.3409090909090909\n","single_context_accuracy 0.3787878787878788\n","sr_accuracy 0.10606060606060606\n","cr_accuracy 0.03787878787878788\n","#########Sentence##########\n","over_all accuracy 0.30177514792899407\n","single_original_accuracy 0.3431952662721893\n","single_semantic_accuracy 0.2781065088757396\n","single_context_accuracy 0.28402366863905326\n","sr_accuracy 0.10059171597633136\n","cr_accuracy 0.03550295857988166\n","#########All data##########\n","over_all accuracy 0.32115171650055374\n","single_original_accuracy 0.33222591362126247\n","single_semantic_accuracy 0.30564784053156147\n","single_context_accuracy 0.32558139534883723\n","sr_accuracy 0.10299003322259136\n","cr_accuracy 0.036544850498338874\n","Loading tiiuae/falcon-7b\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cce0ded984234fdd8d521be94f6611ca","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Running tiiuae/falcon-7b\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 903/903 [07:08<00:00,  2.11it/s]"]},{"name":"stdout","output_type":"stream","text":["#########Wordplay##########\n","over_all accuracy 0.31313131313131315\n","single_original_accuracy 0.3333333333333333\n","single_semantic_accuracy 0.32575757575757575\n","single_context_accuracy 0.2803030303030303\n","sr_accuracy 0.15151515151515152\n","cr_accuracy 0.045454545454545456\n","#########Sentence##########\n","over_all accuracy 0.28205128205128205\n","single_original_accuracy 0.26627218934911245\n","single_semantic_accuracy 0.2781065088757396\n","single_context_accuracy 0.30177514792899407\n","sr_accuracy 0.0650887573964497\n","cr_accuracy 0.01775147928994083\n","#########All data##########\n","over_all accuracy 0.2956810631229236\n","single_original_accuracy 0.2956810631229236\n","single_semantic_accuracy 0.29900332225913623\n","single_context_accuracy 0.292358803986711\n","sr_accuracy 0.10299003322259136\n","cr_accuracy 0.029900332225913623\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\n","models = [\n","#     'mistralai/Mistral-7B-Instruct-v0.2',\n","#     'mistralai/Mistral-7B-v0.3',\n","#     \"meta-llama/Meta-Llama-3-8B-Instruct\",\n","    \"meta-llama/Meta-Llama-3-8B\",\n","#     \"allenai/OLMo-7B-Instruct\",\n","    \"tiiuae/falcon-7b-instruct\",\n","    \"tiiuae/falcon-7b\",\n","]\n","\n","for model_path_tmp in models:\n","    run_with_model(model_path_tmp)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T20:28:00.365989Z","iopub.status.busy":"2024-05-27T20:28:00.365725Z","iopub.status.idle":"2024-05-27T20:28:00.373045Z","shell.execute_reply":"2024-05-27T20:28:00.372120Z","shell.execute_reply.started":"2024-05-27T20:28:00.365964Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4946147,"sourceId":8329940,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
