{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Brain teaser\n","\n","[Original Github REPO](https://github.com/1171-jpg/BrainTeaser)\n","\n","[Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:46:55.023935Z","iopub.status.busy":"2024-05-27T19:46:55.022955Z","iopub.status.idle":"2024-05-27T19:47:28.606417Z","shell.execute_reply":"2024-05-27T19:47:28.605436Z","shell.execute_reply.started":"2024-05-27T19:46:55.023890Z"},"trusted":true},"outputs":[],"source":["!pip install -q -U langchain transformers bitsandbytes accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:28.608575Z","iopub.status.busy":"2024-05-27T19:47:28.608277Z","iopub.status.idle":"2024-05-27T19:47:46.050067Z","shell.execute_reply":"2024-05-27T19:47:46.049306Z","shell.execute_reply.started":"2024-05-27T19:47:28.608544Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import json\n","from datasets import load_dataset\n","from random import shuffle\n","import random\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","\n","import torch\n","from torch.nn.functional import normalize\n","from transformers import AutoModel, AutoTokenizer\n","\n","from tqdm.auto import tqdm\n","import numpy as np\n","import os\n","from transformers import StoppingCriteriaList\n","\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.051631Z","iopub.status.busy":"2024-05-27T19:47:46.051090Z","iopub.status.idle":"2024-05-27T19:47:46.063454Z","shell.execute_reply":"2024-05-27T19:47:46.061981Z","shell.execute_reply.started":"2024-05-27T19:47:46.051604Z"},"trusted":true},"outputs":[],"source":["# Ako imamo vise ponudenih odgovora od 4, da postupak bude automatski u svim funkcijama\n","letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'][:4]\n","letters, len(letters)"]},{"cell_type":"markdown","metadata":{},"source":["## Metrike\n","\n","Preuzeto direktno s njihovog repoa"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2024-05-27T19:47:46.067736Z","iopub.status.busy":"2024-05-27T19:47:46.067398Z","iopub.status.idle":"2024-05-27T19:47:46.086849Z","shell.execute_reply":"2024-05-27T19:47:46.086052Z","shell.execute_reply.started":"2024-05-27T19:47:46.067695Z"},"trusted":true},"outputs":[],"source":["import json\n","from tqdm import tqdm\n","import torch\n","import logging\n","import argparse\n","import numpy as np\n","\n","def getResultdata(result_data):\n","    choice_to_index = {letters[i]: i for i in range(len(letters))}\n","    choice_to_index[None] = len(letters)\n","\n","    word_play = {}\n","    reverse_play = {}\n","    for item in result_data:\n","        item_type = item['id'].split(\"-\")[0]\n","        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n","        if item_type == 'WP':\n","            if item_id not in word_play:\n","                word_play[item_id] = [0,0,0]\n","        else:\n","            if item_id not in reverse_play:\n","                reverse_play[item_id] = [0,0,0]\n","\n","    for item in result_data:\n","        item_type = item['id'].split(\"-\")[0]\n","        item_id = item['id'].split(\"-\")[1].split(\"_\")[0]\n","        ad_type = 0\n","        if 'SR' in item['id']:\n","            ad_type = 1\n","        elif 'CR' in item['id']:\n","            ad_type = 2\n","        else:\n","            ad_type = 0\n","\n","        if item_type == 'WP':\n","            if choice_to_index[item['predict']] == item['label']:\n","                word_play[item_id][ad_type] = 1\n","        else:\n","            if choice_to_index[item['predict']] == item['label']:\n","                reverse_play[item_id][ad_type] = 1\n","                \n","    return word_play,reverse_play\n","\n","\n","def getMetric(data_list):\n","    data_list = np.array(data_list)\n","    overall_accuracy = np.sum(data_list)/3/len(data_list)\n","    original_accuracy = np.sum(data_list,axis = 0)[0]/len(data_list)\n","    semantic_accuracy = np.sum(data_list,axis = 0)[1]/len(data_list)\n","    context_accuracy = np.sum(data_list,axis = 0)[2]/len(data_list)\n","    ori_sema = np.sum([1 if item[0]==1 and item[1] == 1 else 0 for item in data_list])/len(data_list)\n","    ori_sema_cont = np.sum([1 if item[0]==1 and item[1] == 1 and item[2] == 1  else 0 for item in data_list])/len(data_list)\n","    \n","    print(\"over_all accuracy {}\".format(overall_accuracy))\n","    print(\"single_original_accuracy {}\".format(original_accuracy))\n","    print(\"single_semantic_accuracy {}\".format(semantic_accuracy))\n","    print(\"single_context_accuracy {}\".format(context_accuracy))\n","    print(\"sr_accuracy {}\".format(ori_sema))\n","    print(\"cr_accuracy {}\".format(ori_sema_cont))\n","\n","    return {'over_all accuracy':overall_accuracy,'original_accuracy':original_accuracy,'semantic_accuracy':semantic_accuracy,'context_accuracy':context_accuracy,'ori_sema':ori_sema,'ori_sema_cont':ori_sema_cont}\n","\n","\n","def getSeperateResult(word_play,reverse_thinking):\n","    final_result = {}\n","    word_data_list = []\n","    word_data_list = list(word_play.values())\n","    print('#########Wordplay##########')\n","    final_result['wordplay'] = getMetric(word_data_list)\n","    \n","    reverse_data_list = []\n","    for item in reverse_thinking.values():\n","        reverse_data_list.append(item)\n","    print('#########Sentence##########')   \n","    final_result['sentence'] = getMetric(reverse_data_list)  \n","    \n","    \n","    all_data = word_data_list + reverse_data_list\n","    print('#########All data##########') \n","    final_result['all'] = getMetric(all_data) \n","    \n","    return final_result"]},{"cell_type":"markdown","metadata":{},"source":["### Spremanje datoteka\n","\n","Automatski dodaje +1 na naziv ako vec postoji takva datoteka\n","\n","Uzima format model_name + name + redni broj za datoteku\n","\n","Unutra pise prvi testni primjer (example) i rezultate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.087966Z","iopub.status.busy":"2024-05-27T19:47:46.087733Z","iopub.status.idle":"2024-05-27T19:47:46.100371Z","shell.execute_reply":"2024-05-27T19:47:46.099578Z","shell.execute_reply.started":"2024-05-27T19:47:46.087945Z"},"trusted":true},"outputs":[],"source":["def save(final_result, name=None, few_shot=False, example=format):\n","    try:\n","        os.mkdir('results')\n","    except:\n","        pass\n","    model_name = model_path.split('/')[-1]\n","    inserted_name = \"\" if name is None else \"_\" + name\n","    i = 1\n","    while True:\n","        file_path = f'results/{model_name}{inserted_name}_{i}.txt'\n","        try:\n","            with open(file_path, 'r'):\n","                i += 1\n","        except:\n","            with open(file_path, 'w') as file:\n","                file.write(model_name+'\\n')\n","                if few_shot:\n","                    file.write(few_shot + '\\n')\n","                if not isinstance(example, str):\n","                    example = json.dumps(example)\n","                file.write(example + '\\n')\n","                file.write(json.dumps(final_result, indent=4))\n","                return"]},{"cell_type":"markdown","metadata":{},"source":["### Load the model\n","\n","Login kako bi se mogli ucitati napredniji modeli"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.101858Z","iopub.status.busy":"2024-05-27T19:47:46.101447Z","iopub.status.idle":"2024-05-27T19:47:46.137531Z","shell.execute_reply":"2024-05-27T19:47:46.136701Z","shell.execute_reply.started":"2024-05-27T19:47:46.101826Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"markdown","metadata":{},"source":["Logiranje u huggingiface\n","treba kljuc, njega nabavite na huggingface stranici"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.139574Z","iopub.status.busy":"2024-05-27T19:47:46.138872Z","iopub.status.idle":"2024-05-27T19:47:46.239439Z","shell.execute_reply":"2024-05-27T19:47:46.238563Z","shell.execute_reply.started":"2024-05-27T19:47:46.139540Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","login('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', add_to_git_credential=False, write_permission=True)"]},{"cell_type":"markdown","metadata":{},"source":["BitsAndBytesConfig je novi, to kao kvantizira model pa stane na graficku"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.240935Z","iopub.status.busy":"2024-05-27T19:47:46.240673Z","iopub.status.idle":"2024-05-27T19:47:46.244491Z","shell.execute_reply":"2024-05-27T19:47:46.243627Z","shell.execute_reply.started":"2024-05-27T19:47:46.240913Z"},"trusted":true},"outputs":[],"source":["# !pip install ai2-olmo"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:47:46.245841Z","iopub.status.busy":"2024-05-27T19:47:46.245557Z","iopub.status.idle":"2024-05-27T19:51:24.169756Z","shell.execute_reply":"2024-05-27T19:51:24.168879Z","shell.execute_reply.started":"2024-05-27T19:47:46.245817Z"},"trusted":true},"outputs":[],"source":["\n","# model_path = 'google/flan-t5-xxl'\n","# model_path = 'google/flan-t5-xl'\n","# model_path = 'google/flan-t5-large'\n","# model_path = 'mistralai/Mistral-7B-Instruct-v0.2'\n","# model_path = 'mistralai/Mistral-7B-v0.3'\n","# model_path = 'microsoft/phi-2'\n","# model_path = 'microsoft/Phi-3-mini-128k-instruct'\n","# model_path = 'microsoft/Phi-3-mini-4k-instruct'\n","# model_path = '01-ai/Yi-1.5-6B'\n","# model_path = 'netcat420/MFANN3bv0.6'\n","# model_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","# model_path = \"meta-llama/Meta-Llama-3-8B\"\n","# model_path = \"allenai/OLMo-7B-Instruct\"\n","# model_path = \"tiiuae/falcon-7b-instruct\"\n","model_path = \"tiiuae/falcon-7b\"\n","# model_path = 'Intel/neural-chat-7b-v3-1'\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","def get_mistral():\n","    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_path,\n","        device_map=\"auto\",\n","        quantization_config=quantization_config,\n","        trust_remote_code=True,\n","    )\n","    return tokenizer, model\n","\n","def get_llama():\n","    tokenizer = AutoTokenizer.from_pretrained(model_path)\n","    model_4bit = AutoModelForCausalLM.from_pretrained(\n","        model_path,\n","#         \"SweatyCrayfish/llama-3-8b-quantized\", \n","#         load_in_4bit=True, \n","#         torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        quantization_config=quantization_config,\n","    )\n","    return tokenizer, model_4bit\n","\n","tokenizer, model = get_mistral()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset\n","\n","- Skinuti s [linka](https://drive.google.com/drive/u/0/folders/1kiFXp5fqpf8--NQJJAlBIBpfSaXTk1UY)\n","\n","- Staviti u folder `/data`, ako na Kaggleu, onda napraviti svoj dataset te ga dodati pod input"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.173306Z","iopub.status.busy":"2024-05-27T19:51:24.173008Z","iopub.status.idle":"2024-05-27T19:51:24.197324Z","shell.execute_reply":"2024-05-27T19:51:24.196471Z","shell.execute_reply.started":"2024-05-27T19:51:24.173280Z"},"trusted":true},"outputs":[],"source":["# few_shot_examples = list(np.load(\"./{dataset_path}/data/demonstration.npy\",allow_pickle=True))\n","data_path = '/kaggle/input/brainteaser/data'\n","sentence_data_path = f\"{data_path}/SP-train.npy\"\n","wordplay_data_list = f\"{data_path}/WP-train.npy\"\n","sentence_data_list = list(np.load(sentence_data_path,allow_pickle=True))\n","wordplay_data_list = list(np.load(wordplay_data_list,allow_pickle=True))\n","\n","test_data_list = sentence_data_list + wordplay_data_list\n","print(f\"Dataset length {len(test_data_list)}\")"]},{"cell_type":"markdown","metadata":{},"source":["Format za mystral, za ostale modele maknuti linije `<s>[INST]`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.198506Z","iopub.status.busy":"2024-05-27T19:51:24.198251Z","iopub.status.idle":"2024-05-27T19:51:24.254936Z","shell.execute_reply":"2024-05-27T19:51:24.254080Z","shell.execute_reply.started":"2024-05-27T19:51:24.198483Z"},"trusted":true},"outputs":[],"source":["format = \"\"\n","def get_format():\n","    global format\n","    newline = '\\n'\n","    format = f\"\"\"Question: {\"{}\"}\n","Choice:\n","{''.join('(' + x + ') {}' + newline for x in letters)}\"\"\"\n","    return format\n","\n","def get_llama_format(demonstration=None):\n","    global tokenizer, format\n","    messages = []\n","    if demonstration is not None:\n","        messages.append({\"role\": \"system\", \"content\": demonstration})\n","    messages.append({\"role\": \"user\", \"content\": get_format()})\n","    messages.append({\"role\": \"assistant\", \"content\": \"Answer:(\"})\n","    try:\n","        format = tokenizer.apply_chat_template(messages, tokenize=False)\n","    except Exception:\n","        # When using mistral model, roles in messages must alternate, this way it works without errors\n","        messages[1][\"content\"] = demonstration + \"\\n\\n\" + messages[1][\"content\"]\n","        format = tokenizer.apply_chat_template(messages[1:], tokenize=False)\n","    # remove \"<|eot_id|>\" from the end\n","    format = format[:format.index(\"Answer:(\")+8]\n","\n","def get_appended_format(demonstration=None):\n","    global format\n","    format = get_format()\n","    if demonstration is not None:\n","        format = demonstration + \"\\n\\n\" + format\n","    format += \"\\nAnswer:(\"\n","\n","get_llama_format(\"Primjer\")\n","print(format)\n","get_appended_format()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.256336Z","iopub.status.busy":"2024-05-27T19:51:24.255882Z","iopub.status.idle":"2024-05-27T19:51:24.261244Z","shell.execute_reply":"2024-05-27T19:51:24.260375Z","shell.execute_reply.started":"2024-05-27T19:51:24.256312Z"},"trusted":true},"outputs":[],"source":["def get_single_demo(sample):\n","    global format\n","    sample_demo = format.format(\n","        sample['question'], *sample['choice_list'])\n","    return sample_demo\n","\n","good_responses = [f'{x})' for x in letters]\n","print(\"good_responses\", good_responses)"]},{"cell_type":"markdown","metadata":{},"source":["## Generiranje dataseta\n","\n","### Pomocne funkcije"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.262641Z","iopub.status.busy":"2024-05-27T19:51:24.262352Z","iopub.status.idle":"2024-05-27T19:51:24.270592Z","shell.execute_reply":"2024-05-27T19:51:24.269719Z","shell.execute_reply.started":"2024-05-27T19:51:24.262609Z"},"trusted":true},"outputs":[],"source":["def set_predictions(data_list):\n","    \"\"\"Uzima response i parsira ga tako da pod predict stavi slovo koje je napisano\"\"\"\n","    for index,item in enumerate(data_list):\n","        item['predict'] = None\n","        for x in letters:\n","            if (f'{x})') in item['response']:\n","                item['predict'] = x\n","\n","        if item['predict'] is None:\n","            print(index)\n","\n","def custom_stopping_criteria(input_ids: torch.LongTensor, score: torch.FloatTensor, **kwargs) -> bool:\n","    \"\"\"\n","    Funkcija kako bi se dinamicki prepoznalo kad treba prestati generirati tekst:\n","    ne nakon fiksnog broja tokena, vec kad model napise rjesenje. Najcesce\n","    ce to ipak biti medu prva dva tokena\n","    \"\"\"\n","    decoded = tokenizer.decode(input_ids[0][-3:])\n","    for good_response in good_responses:\n","        if good_response in decoded:\n","            return True\n","    return False\n","\n","stopping_criteria = StoppingCriteriaList([custom_stopping_criteria])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.272112Z","iopub.status.busy":"2024-05-27T19:51:24.271754Z","iopub.status.idle":"2024-05-27T19:51:24.284875Z","shell.execute_reply":"2024-05-27T19:51:24.283997Z","shell.execute_reply.started":"2024-05-27T19:51:24.272057Z"},"trusted":true},"outputs":[],"source":["def generate(samples, tokens=10, all_tokens=True, few_shot=False):\n","    global model\n","    for sample in tqdm(samples):\n","        if few_shot:\n","            text = demonstration + get_single_demo(sample)\n","        else:\n","            text = get_single_demo(sample)\n","        inputs = tokenizer.encode(text, return_tensors=\"pt\", return_attention_mask=False).to(device)\n","        original_tokens = len(inputs[0])\n","        outputs = model.generate(\n","            inputs,\n","            pad_token_id=tokenizer.eos_token_id,\n","            do_sample = False,\n","            max_new_tokens=tokens,\n","            stopping_criteria=stopping_criteria\n","        )\n","        outputs = outputs[0][0 if all_tokens else original_tokens:]\n","        sample['response'] = tokenizer.decode(outputs)\n","    set_predictions(samples)"]},{"cell_type":"markdown","metadata":{},"source":["## Testiranje"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:24.286265Z","iopub.status.busy":"2024-05-27T19:51:24.285893Z","iopub.status.idle":"2024-05-27T19:51:30.035653Z","shell.execute_reply":"2024-05-27T19:51:30.034799Z","shell.execute_reply.started":"2024-05-27T19:51:24.286230Z"},"trusted":true},"outputs":[],"source":["get_llama_format()\n","generate(test_data_list[:10], tokens=1000, all_tokens=False, few_shot=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:30.037236Z","iopub.status.busy":"2024-05-27T19:51:30.036902Z","iopub.status.idle":"2024-05-27T19:51:30.041949Z","shell.execute_reply":"2024-05-27T19:51:30.041060Z","shell.execute_reply.started":"2024-05-27T19:51:30.037175Z"},"trusted":true},"outputs":[],"source":["for sample in test_data_list[:10]:\n","    print(\"\\n>\", sample['response'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:30.043451Z","iopub.status.busy":"2024-05-27T19:51:30.043152Z","iopub.status.idle":"2024-05-27T19:51:33.450799Z","shell.execute_reply":"2024-05-27T19:51:33.449822Z","shell.execute_reply.started":"2024-05-27T19:51:30.043426Z"},"trusted":true},"outputs":[],"source":["get_llama_format()\n","text = get_single_demo(test_data_list[1])\n","inputs = tokenizer.encode(text, return_tensors=\"pt\", return_attention_mask=False).to(device)\n","outputs = model.generate(\n","    inputs,\n","    pad_token_id=tokenizer.eos_token_id,\n","    do_sample = False,\n","    max_new_tokens=50,\n",")\n","print(tokenizer.decode(outputs[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.452396Z","iopub.status.busy":"2024-05-27T19:51:33.452054Z","iopub.status.idle":"2024-05-27T19:51:33.458756Z","shell.execute_reply":"2024-05-27T19:51:33.457826Z","shell.execute_reply.started":"2024-05-27T19:51:33.452352Z"},"trusted":true},"outputs":[],"source":["# generate(test_data_list, tokens=20, all_tokens=False, few_shot=False)\n","\n","# word_play,sentence_play = getResultdata(test_data_list)\n","# # word_play,sentence_play = getResultdata(test_data_list)\n","# final_result = getSeperateResult(word_play, sentence_play)\n","\n","# save(final_result, name=\"with-instruction\", example=get_single_demo(test_data_list[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.460333Z","iopub.status.busy":"2024-05-27T19:51:33.459840Z","iopub.status.idle":"2024-05-27T19:51:33.467208Z","shell.execute_reply":"2024-05-27T19:51:33.466338Z","shell.execute_reply.started":"2024-05-27T19:51:33.460282Z"},"trusted":true},"outputs":[],"source":["demonstration1 = \"Please pick the best choice for the brain teaser. Each brain teaser has only one possible solution including the choice none of above, answer should only provide the choice:\"\n","demonstration2 = \"The following question is a brainteaser. One choice is correct, other choices are semanticaly derived from the question.\"\n","demonstration3 = \"The following question is a brainteaser.\"\n","demonstration4 = \"The following question is a brainteaser. One choice is correct, other choices are semanticaly derived from the question. Sometimes none of the above is correct.\"\n","demonstration5 = \"The following question is a brainteaser. Sometimes none of the above is correct.\""]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-05-24T12:31:13.723172Z","iopub.status.busy":"2024-05-24T12:31:13.722785Z","iopub.status.idle":"2024-05-24T12:31:14.068435Z","shell.execute_reply":"2024-05-24T12:31:14.067422Z","shell.execute_reply.started":"2024-05-24T12:31:13.723141Z"}},"source":["\n","\n","- `The following question is a brainteaser. One choice is correct, other choices are semanticaly derived from the question. Sometimes none of the above is correct.`\n","\n","- `The following question is a brainteaser. One choice is correct, other choices are semanticaly derived from the question.`\n","\n","- `The following question is a brainteaser.` (less informative, helpful) \n","\n","- `Please pick the best choice for the brain teaser. Each brain teaser has only one possible solution including the choice none of above, answer should only provide the choice:` (Original, more informative, helpful) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.468688Z","iopub.status.busy":"2024-05-27T19:51:33.468424Z","iopub.status.idle":"2024-05-27T19:51:33.477359Z","shell.execute_reply":"2024-05-27T19:51:33.476433Z","shell.execute_reply.started":"2024-05-27T19:51:33.468664Z"},"trusted":true},"outputs":[],"source":["def generate_and_save(test_data_list, name=\"normal\"):\n","    generate(test_data_list, tokens=20, all_tokens=False, few_shot=False)\n","\n","    word_play,sentence_play = getResultdata(test_data_list)\n","    # word_play,sentence_play = getResultdata(test_data_list)\n","    final_result = getSeperateResult(word_play, sentence_play)\n","\n","    save(final_result, name=name, example=get_single_demo(test_data_list[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.480658Z","iopub.status.busy":"2024-05-27T19:51:33.480402Z","iopub.status.idle":"2024-05-27T19:51:33.486346Z","shell.execute_reply":"2024-05-27T19:51:33.485593Z","shell.execute_reply.started":"2024-05-27T19:51:33.480635Z"},"trusted":true},"outputs":[],"source":["def generate_with_demonstration(demonstration=None,test_data_list=test_data_list, name=\"with-instruction\", llama_format=False):\n","    if llama_format:\n","        get_llama_format(demonstration)\n","    else:\n","        get_appended_format(demonstration)\n","    generate_and_save(test_data_list, name=name)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.487950Z","iopub.status.busy":"2024-05-27T19:51:33.487596Z","iopub.status.idle":"2024-05-27T19:51:33.500682Z","shell.execute_reply":"2024-05-27T19:51:33.499846Z","shell.execute_reply.started":"2024-05-27T19:51:33.487910Z"},"trusted":true},"outputs":[],"source":["get_llama_format(\"jalo\")\n","print(format[:format.index(\"Answer:(\")+8])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["This question is a brainteaser.\n","\n","Question: {}\n","Choice:\n","(A) {}\n","(B) {}\n","(C) {}\n","(D) {}\n","\n","Answer:("]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.501923Z","iopub.status.busy":"2024-05-27T19:51:33.501691Z","iopub.status.idle":"2024-05-27T19:51:33.509317Z","shell.execute_reply":"2024-05-27T19:51:33.508499Z","shell.execute_reply.started":"2024-05-27T19:51:33.501902Z"},"trusted":true},"outputs":[],"source":["# save({}, name=\"normal\", example=get_single_demo(test_data_list[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.510516Z","iopub.status.busy":"2024-05-27T19:51:33.510253Z","iopub.status.idle":"2024-05-27T19:51:33.518497Z","shell.execute_reply":"2024-05-27T19:51:33.517721Z","shell.execute_reply.started":"2024-05-27T19:51:33.510493Z"},"trusted":true},"outputs":[],"source":["# generate_with_demonstration(test_data_list[:10]+ test_data_list[-10:], name=\"normal\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.519856Z","iopub.status.busy":"2024-05-27T19:51:33.519387Z","iopub.status.idle":"2024-05-27T19:51:33.528496Z","shell.execute_reply":"2024-05-27T19:51:33.527743Z","shell.execute_reply.started":"2024-05-27T19:51:33.519831Z"},"trusted":true},"outputs":[],"source":["# generate_with_demonstration(name=\"normal\")\n","# generate_with_demonstration(demonstration1, name=\"dem1\")\n","# generate_with_demonstration(demonstration3, name=\"dem3\")\n","# generate_with_demonstration(demonstration2, name=\"dem2\")\n","# generate_with_demonstration(demonstration4, name=\"dem4\")\n","\n","# generate_with_demonstration(name=\"normal-spec\")\n","# generate_with_demonstration(demonstration1, name=\"dem1-spec\", llama_format=True)\n","# generate_with_demonstration(demonstration3, name=\"dem3-spec\", llama_format=True)\n","# generate_with_demonstration(demonstration2, name=\"dem2-spec\", llama_format=True)\n","# generate_with_demonstration(demonstration4, name=\"dem4-spec\", llama_format=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.529583Z","iopub.status.busy":"2024-05-27T19:51:33.529356Z","iopub.status.idle":"2024-05-27T19:51:33.540842Z","shell.execute_reply":"2024-05-27T19:51:33.539968Z","shell.execute_reply.started":"2024-05-27T19:51:33.529562Z"},"trusted":true},"outputs":[],"source":["test_data_list[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.542311Z","iopub.status.busy":"2024-05-27T19:51:33.541963Z","iopub.status.idle":"2024-05-27T19:51:33.548773Z","shell.execute_reply":"2024-05-27T19:51:33.547997Z","shell.execute_reply.started":"2024-05-27T19:51:33.542279Z"},"trusted":true},"outputs":[],"source":["model = None\n","def run_with_model(model_path_tmp):\n","    global tokenizer, model, model_path\n","    del model\n","    model = None\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    model_path = model_path_tmp\n","    print(f\"Loading {model_path}\")\n","    tokenizer, model = get_mistral()\n","\n","    print(f\"Running {model_path}\")\n","    generate_with_demonstration(demonstration5, name=\"dem5\")\n","    if 'instruct' in model_path or 'Instruct' in model_path:\n","        generate_with_demonstration(demonstration5, name=\"dem5-spec\", llama_format=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T19:51:33.553640Z","iopub.status.busy":"2024-05-27T19:51:33.552895Z","iopub.status.idle":"2024-05-27T20:28:00.362932Z","shell.execute_reply":"2024-05-27T20:28:00.361001Z","shell.execute_reply.started":"2024-05-27T19:51:33.553614Z"},"trusted":true},"outputs":[],"source":["\n","models = [\n","#     'mistralai/Mistral-7B-Instruct-v0.2',\n","#     'mistralai/Mistral-7B-v0.3',\n","#     \"meta-llama/Meta-Llama-3-8B-Instruct\",\n","    \"meta-llama/Meta-Llama-3-8B\",\n","#     \"allenai/OLMo-7B-Instruct\",\n","    \"tiiuae/falcon-7b-instruct\",\n","    \"tiiuae/falcon-7b\",\n","]\n","\n","for model_path_tmp in models:\n","    run_with_model(model_path_tmp)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4946147,"sourceId":8329940,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
