{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain teaser\n",
    "\n",
    "[Original Github REPO](https://github.com/1171-jpg/BrainTeaser)\n",
    "\n",
    "\n",
    "### Upute za pokretanje\n",
    "\n",
    "1) Pokrenuti donju liniju i viditi jel se sve moze importati\n",
    "1) Skinuti sve sto se ne moze sa `!pip install` unutar notebooka\n",
    "(pip bi trebao raditi i s condom ako je dobro namjesteno)\n",
    "    - Skinuti pytorch sa stranice [Pytorch](https://pytorch.org/get-started/locally/) - odaberite CUDA 11.8\n",
    "    ako imate graficku. Meni je bilo:\n",
    "    `> !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`\n",
    "    - Ako nemate CUDA, notebook ce biti sporiji - dovoljan za inference, \n",
    "    ali nedovoljan za fine-tuning (sreca pa to niti ne radimo, bilo bi presporo \n",
    "    i s grafickom)\n",
    "    - Skinuti huggingface transformers library:\n",
    "    `> pip install 'transformers[torch]'`\n",
    "1) Moze se sve importati na Kaggle, ovo mozda malo kasnije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from utils import getMetric, getSeperateResult, getResultdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "- Skinuti s [linka](https://drive.google.com/drive/u/0/folders/1kiFXp5fqpf8--NQJJAlBIBpfSaXTk1UY)\n",
    "\n",
    "- Staviti u folder `/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "# model_path = 'google/flan-t5-xxl'\n",
    "# model_path = 'google/flan-t5-xl'\n",
    "model_path = 'google/flan-t5-large'\n",
    "# model_path = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# model_path = 'microsoft/phi-2'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "if model_path.find('flan') >= 0:\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = model.to(device)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Changing device to cpu\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# few_shot_examples = list(np.load(\"./{dataset_path}/data/demonstration.npy\",allow_pickle=True))\n",
    "sentence_data_path = \"data/SP-train.npy\"\n",
    "wordplay_data_list = \"data/WP-train.npy\"\n",
    "sentence_data_list = list(np.load(sentence_data_path,allow_pickle=True))\n",
    "wordplay_data_list = list(np.load(wordplay_data_list,allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length 903\n"
     ]
    }
   ],
   "source": [
    "test_data_list = sentence_data_list + wordplay_data_list\n",
    "print(f\"Dataset length {len(test_data_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"The following question is a brainteaser. Choose the answer using elimination method. However, eliminate all the choices that are obvious from the question and respond with the least likely one.\"\n",
    "\n",
    "format = \\\n",
    "\"\"\"\n",
    "Question: {}\n",
    "\n",
    "What is the correct answer to the question from the following choices?\n",
    "(A) {}\n",
    "(B) {}\n",
    "(C) {}\n",
    "(D) {}\n",
    "\"\"\"\n",
    "\n",
    "def get_sample_demo(sample):\n",
    "    sample_demo = format.format(sample['question'],sample['choice_list'][0],sample['choice_list'][1],sample['choice_list'][2],sample['choice_list'][3])\n",
    "    \n",
    "    return sample_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following question is a brainteaser. Choose the answer using elimination method. However, eliminate all the choices that are obvious from the question and respond with the least likely one.\n",
      "\n",
      "Question: Mr. and Mrs. Mustard have six daughters and each daughter has one brother. But there are only 9 people in the family, how is that possible?\n",
      "\n",
      "What is the correct answer to the question from the following choices?\n",
      "(A) Some daughters get married and have their own family.\n",
      "(B) Each daughter shares the same brother.\n",
      "(C) Some brothers were not loved by family and moved away.\n",
      "(D) None of above.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_sample_demo(test_data_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 903/903 [01:25<00:00, 10.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "for sample in tqdm(test_data_list):\n",
    "    inputs = tokenizer.encode(get_sample_demo(sample), return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs, max_new_tokens=10000)\n",
    "    sample['response'] = tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,item in enumerate(test_data_list):\n",
    "    try:\n",
    "        item['predict'] = item['response'].split('(')[1].strip().split(')')[0].strip()\n",
    "    except:\n",
    "        try:\n",
    "            item['predict'] = item['response'].split('> ')[1].strip().split('</')[0].strip()\n",
    "        except:\n",
    "            item['predict'] = None\n",
    "            print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########Wordplay##########\n",
      "over_all accuracy 0.19949494949494948\n",
      "single_original_accuracy 0.18181818181818182\n",
      "single_semantic_accuracy 0.1893939393939394\n",
      "single_context_accuracy 0.22727272727272727\n",
      "sr_accuracy 0.13636363636363635\n",
      "cr_accuracy 0.09090909090909091\n",
      "#########Sentence##########\n",
      "over_all accuracy 0.14990138067061143\n",
      "single_original_accuracy 0.14792899408284024\n",
      "single_semantic_accuracy 0.13609467455621302\n",
      "single_context_accuracy 0.16568047337278108\n",
      "sr_accuracy 0.08284023668639054\n",
      "cr_accuracy 0.04142011834319527\n",
      "#########All data##########\n",
      "over_all accuracy 0.1716500553709856\n",
      "single_original_accuracy 0.16279069767441862\n",
      "single_semantic_accuracy 0.15946843853820597\n",
      "single_context_accuracy 0.19269102990033224\n",
      "sr_accuracy 0.10631229235880399\n",
      "cr_accuracy 0.06312292358803986\n"
     ]
    }
   ],
   "source": [
    "word_play,sentence_play = getResultdata(test_data_list)\n",
    "final_result = getSeperateResult(word_play,sentence_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordplay': {'over_all accuracy': 0.19949494949494948,\n",
       "  'original_accuracy': 0.18181818181818182,\n",
       "  'semantic_accuracy': 0.1893939393939394,\n",
       "  'context_accuracy': 0.22727272727272727,\n",
       "  'ori_sema': 0.13636363636363635,\n",
       "  'ori_sema_cont': 0.09090909090909091},\n",
       " 'sentence': {'over_all accuracy': 0.14990138067061143,\n",
       "  'original_accuracy': 0.14792899408284024,\n",
       "  'semantic_accuracy': 0.13609467455621302,\n",
       "  'context_accuracy': 0.16568047337278108,\n",
       "  'ori_sema': 0.08284023668639054,\n",
       "  'ori_sema_cont': 0.04142011834319527},\n",
       " 'all': {'over_all accuracy': 0.1716500553709856,\n",
       "  'original_accuracy': 0.16279069767441862,\n",
       "  'semantic_accuracy': 0.15946843853820597,\n",
       "  'context_accuracy': 0.19269102990033224,\n",
       "  'ori_sema': 0.10631229235880399,\n",
       "  'ori_sema_cont': 0.06312292358803986}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_path.split('/')[-1]\n",
    "with open(f'results/{model_name}-least-likely.txt', 'w') as file:\n",
    "    file.write(model_name)\n",
    "    file.write(json.dumps(final_result, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
